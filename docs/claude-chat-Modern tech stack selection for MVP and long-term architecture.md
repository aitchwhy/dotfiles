# Modern tech stack selection for MVP and long-term architecture

**Created:** 11/25/2025 11:51:46  
**Updated:** 11/25/2025 13:11:20  
**Exported:** 11/25/2025 13:33:12  
**Link:** [https://claude.ai/chat/43b85f57-06d6-4224-bf39-1ee57e00ce25](https://claude.ai/chat/43b85f57-06d6-4224-bf39-1ee57e00ce25)  

## Prompt:
11/25/2025, 11:51:52 AM

Continue the conversation here. Attached file marked down so that I can finish the last response and help you decide the final, up-to-date today, November 25th, 2025, latest Martin set of selections so I can get started and fix this tech stack freeze. It should fulfill my requirements and be cutting-edge without getting overly complex still future-proof because I own the data, the schemas, the code, the workflows, and such on managed platforms so that I can get the MVP done. And separately, also tech stack for forever, longer-term tech stack, and with reasons and occasions when I would need them, and with rationale as a kind of a reference so that it's a menu.



## Response:
11/25/2025, 11:54:30 AM

````plaintext
Thought process: Thinking about selecting cutting-edge tech stacks for MVP and long-term scalability.

The user is asking me to continue from an attached conversation about tech stack selection. Let me first read the uploaded file to understand the context and where we left off.
````

````plaintext
View: Reading the attached conversation to understand context and continue from where we left off
````

````plaintext
Thought process

This is a very long document. Let me continue reading to see the full context and where the conversation left off. The document was truncated at line 193. Let me see more of it.
````

````plaintext
View: Reading more of the conversation to understand where it left off
````

````plaintext
Thought process: Assembled context to architect comprehensive tech stack recommendations.

Let me continue reading to understand the full context and where the conversation ended.
````

````plaintext
View: Reading more of the conversation to see where it ended
````

````plaintext
Thought process: Reconnoitered conversation history to contextualize tech stack recommendations.

Let me continue reading the conversation to see where it ended.
````

Let me continue reading where the conversation ended:

````plaintext
View: Reading end of conversation to see where we left off
````

````plaintext
Thought process: Synthesized current tech versions to finalize MVP and forever stacks.

The conversation ended mid-way through the assistant's response - it was searching for the latest TypeScript version and got cut off. The user is now asking me to continue from where we left off and:

1. Finalize the tech stack selections for November 25, 2025
2. Provide the "MVP Stack" for Ember specifically
3. Provide a "Forever Stack" - the longer-term stack with rationale for when to use each option
4. Make it a reference menu

Let me search for the latest versions of key technologies to ensure accuracy, then provide a comprehensive, decisive recommendation.

Key technologies to verify:
- TypeScript (latest stable)
- Bun (latest)
- Next.js (latest)
- React (latest)
- Zod (v4 status)
- Supabase current offerings
- LiveKit Cloud agent hosting
- Vercel capabilities
- Cloudflare Workers/R2

Let me search for the current state of these technologies.
````

Now I understand where we left off. The conversation was cut while verifying latest versions. Let me complete this by searching for current technology versions and giving you the definitive stack decisions.

````plaintext
Web Search: Next.js 15 latest stable version November 2025
````

> **Next.js 15 | Next.js** [nextjs.org](https://nextjs.org/blog/next-15)
>
> **Next.js by Vercel - The React Framework | Next.js by Vercel - The React Framework** [nextjs.org](https://nextjs.org/blog)
>
> **Next.js | endoflife.date** [endoflife.date](https://endoflife.date/nextjs)
>
> **Upgrading: Version 15 | Next.js** [nextjs.org](https://nextjs.org/docs/app/guides/upgrading/version-15)
>
> **Releases · vercel/next.js** [github.com](https://github.com/vercel/next.js/releases)
>
> **Next.js 15.5 | Next.js** [nextjs.org](https://nextjs.org/blog/next-15-5)
>
> **Next.js 15 Stable Release is Live - Pagepro** [pagepro.co](https://pagepro.co/blog/react-tldr/next-js-15-stable-release-is-live/)
>
> **Next.js - Wikipedia** [wikipedia.org](https://en.wikipedia.org/wiki/Next.js)
>
> **Next.js 15 Stable Version Is Here : What's New? - DEV Community** [dev.to](https://dev.to/grenishrai/nextjs-15-stable-version-is-here-3hd2)
>
> **Next.js 15: New Features, Breaking Changes, and Improvements You Need to Know | by David Mostoller | Medium** [medium.com](https://medium.com/@dmostoller/next-js-15-new-features-breaking-changes-and-improvements-you-need-to-know-ac98fa6f0c2d)
>
````plaintext
Thought process

Now I have a good picture. Let me search for Bun, Zod v4, LiveKit Cloud agent hosting, and Supabase's current offerings to complete the picture.
````

````plaintext
Web Search: Bun latest version November 2025 release
````

> **Releases · oven-sh/bun** [github.com](https://github.com/oven-sh/bun/releases)
>
> **Bun v1.3.3 | Bun Blog** [bun.com](https://bun.com/blog/bun-v1.3.3)
>
> **Bun | endoflife.date** [endoflife.date](https://endoflife.date/bun)
>
> **Bun v1.3.2 | Bun Blog** [bun.com](https://bun.com/blog/bun-v1.3.2)
>
> **bun - npm** [npmjs.com](https://www.npmjs.com/package/bun?activeTab=versions)
>
> **Bun — A fast all-in-one JavaScript runtime** [bun.com](https://bun.com)
>
> **Blog | Bun** [bun.sh](https://bun.sh/blog)
>
> **Bun (software) - Wikipedia** [wikipedia.org](https://en.wikipedia.org/wiki/Bun_(software))
>
> **Android 17 ‘Cinnamon Bun’ Codename Confirmed: Release Timeline, Features, and What’s New in Google’s Next Big Update** [bez-kabli.pl](https://www.bez-kabli.pl/news/android-17-cinnamon-bun-codename-confirmed-release-timeline-features-and-whats-new-in-googles-next-big-update/)
>
> **Bun download | SourceForge.net** [sourceforge.net](https://sourceforge.net/projects/bun.mirror/)
>
````plaintext
Thought process

Good - I have confirmed:
- Bun is at v1.3.3 (released Nov 21, 2025)
- Next.js 15.5 is stable, Next.js 16 is coming
- TypeScript 5.9 is stable

Let me search for a few more critical pieces: LiveKit Cloud agent hosting and Supabase's current features.
````

````plaintext
Web Search: LiveKit Cloud agent hosting managed deployment 2025
````

> **Deploy and scale agents on LiveKit Cloud** [livekit.io](https://blog.livekit.io/deploy-and-scale-agents-on-livekit-cloud/)
>
> **Deploying to LiveKit Cloud | LiveKit docs** [livekit.io](https://docs.livekit.io/agents/ops/deployment/)
>
> **LiveKit Cloud | LiveKit docs** [livekit.io](https://docs.livekit.io/home/cloud/)
>
> **LiveKit Agents | LiveKit docs** [livekit.io](https://docs.livekit.io/agents/)
>
> **Pricing | LiveKit** [livekit.io](https://livekit.io/pricing)
>
> **Agent Management | livekit/livekit-cli | DeepWiki** [deepwiki.com](https://deepwiki.com/livekit/livekit-cli/8-agent-management)
>
> **How to deploy LiveKit Agents on Modal | Modal Blog** [modal.com](https://modal.com/blog/livekit-modal)
>
> **Deploying to custom environments | LiveKit docs** [livekit.io](https://docs.livekit.io/agents/ops/deployment/custom/)
>
> **LiveKit | Build voice, video, and physical AI** [livekit.io](https://livekit.io/)
>
> **Agent deployment CLI reference | LiveKit docs** [livekit.io](https://docs.livekit.io/agents/ops/deployment/cli/)
>
````plaintext
Thought process: Validating LiveKit Cloud capabilities and synthesizing optimal stack.

Good - I now have confirmed that LiveKit Cloud does offer managed agent hosting! This is key - the user was right. They can deploy their agent directly to LiveKit Cloud without needing Fly.io. This simplifies the stack significantly.

Let me now search for Supabase's current features and Zod v4 status.
````

````plaintext
Web Search: Supabase features November 2025 storage realtime edge functions
````

> **Supabase Edge Functions - Deploy JavaScript globally in seconds** [supabase.com](https://supabase.com/edge-functions)
>
> **Supabase Release Notes - November 2025 Latest Updates - Releasebot** [releasebot.io](https://releasebot.io/updates/supabase)
>
> **Edge Functions | Supabase Docs** [supabase.com](https://supabase.com/docs/guides/functions)
>
> **Changelog** [supabase.com](https://supabase.com/changelog)
>
> **Supabase Pricing in 2025: Full Breakdown of Plans | UI Bakery Blog** [uibakery.io](https://uibakery.io/blog/supabase-pricing)
>
> **Persistent Storage and 97% Faster Cold Starts for Edge Functions** [supabase.com](https://supabase.com/blog/persistent-storage-for-faster-edge-functions)
>
> **Supabase Features** [supabase.com](https://supabase.com/features)
>
> **Supabase Pricing, Features & Best Alternatives (2025)** [srvrlss.io](https://www.srvrlss.io/provider/supabase/)
>
> **Supabase vs AWS: Feature and Pricing Comparison (2025)** [bytebase.com](https://www.bytebase.com/blog/supabase-vs-aws-pricing/)
>
> **Supabase Edge Functions: Introducing Background Tasks, Ephemeral Storage, and WebSockets - DEV Community** [dev.to](https://dev.to/supabase/supabase-edge-functions-introducing-background-tasks-ephemeral-storage-and-websockets-pe)
>
````plaintext
Thought process: Synthesizing tech stack recommendations with confirmed versions.

Now I have all the information I need to provide a definitive tech stack recommendation. Let me synthesize all this:

**Confirmed versions as of Nov 25, 2025:**
- TypeScript 5.9 (stable)
- Bun 1.3.3 (released Nov 21, 2025)
- Next.js 15.5 (Next.js 16 coming soon)
- React 19 (stable)
- Zod v4 (need to verify but was stable in earlier searches)
- LiveKit Cloud - supports managed agent hosting ($0.01/min)
- Supabase - has Auth, Database, Storage, Edge Functions, Realtime

**Key findings:**
1. LiveKit Cloud DOES offer managed agent hosting - no need for Fly.io!
2. Supabase has all-in-one: Auth (phone OTP), Postgres, Storage (S3-compatible), Edge Functions
3. Bun 1.3.3 is very mature now
4. Next.js 15.5 with Turbopack is production-ready

This means the simplest stack is:
- **Vercel**: Next.js 15.5 (frontend + API routes)
- **Supabase**: Auth + Postgres + Storage
- **LiveKit Cloud**: Realtime + Managed Agent Hosting

That's just 3 vendors! This is much simpler than what was being discussed.

Let me now create the final, definitive tech stack document with both MVP and Forever stacks.
````

````plaintext
Web Search: Zod v4 stable release 2025
````

> **Release notes | Zod** [zod.dev](https://zod.dev/v4)
>
> **Zod v4 Available with Major Performance Improvements and Introduction of Zod Mini - InfoQ** [infoq.com](https://www.infoq.com/news/2025/08/zod-v4-available/)
>
> **Releases · colinhacks/zod** [github.com](https://github.com/colinhacks/zod/releases)
>
> **Versioning | Zod** [zod.dev](https://zod.dev/v4/versioning)
>
> **Migration guide | Zod** [zod.dev](https://zod.dev/v4/changelog)
>
> **For library authors | Zod** [zod.dev](https://zod.dev/library-authors)
>
> **Versioning with subpaths (`"zod/v4"`) to enable incremental migration · Issue #4371 · colinhacks/zod** [github.com](https://github.com/colinhacks/zod/issues/4371)
>
> **Mastra Changelog 2025-09-08 | Mastra Blog** [mastra.ai](https://mastra.ai/blog/changelog-2025-09-08)
>
> **Zod 4 released: enhanced performance and new Zod Mini | AlternativeTo** [alternativeto.net](https://alternativeto.net/news/2025/5/zod-4-released-enhanced-performance-and-new-zod-mini/)
>
> **Zod | Zod** [zod.dev](https://zod.dev/packages/zod)
>
````plaintext
Thought process: Consolidated modern tech stack with three core vendors for MVP launch.

Now I have all the information I need. Let me compile the definitive tech stack document.

**Confirmed Technology Versions as of Nov 25, 2025:**
- TypeScript 5.9 (stable, released Aug 2025)
- Bun 1.3.3 (released Nov 21, 2025)
- Next.js 15.5 (stable, Next.js 16 coming)
- React 19 (stable)
- Zod v4 (stable, 14x faster string parsing, released mid-2025)
- LiveKit Cloud with managed agent hosting ($0.01/min agent sessions)
- Supabase with Auth, Postgres, Storage, Edge Functions, Realtime

**Key Stack Simplification:**
The user was right - LiveKit Cloud now hosts agents directly. This eliminates the need for Fly.io. Combined with Supabase handling everything else (auth, db, storage), we can get down to just 3 vendors for MVP:

1. **Vercel** - Next.js frontend + API routes
2. **Supabase** - Auth + Postgres + Storage
3. **LiveKit Cloud** - Realtime + Agent hosting

Let me now create the comprehensive tech stack document.
````

Now I have all the verified information. Let me provide you with the definitive tech stack decisions.

---

# **Ember Tech Stack: Final Decision Document**
**Date:** November 25, 2025 | **Confidence:** 90%

## **TL;DR**

You were right to push back on vendor sprawl. **The minimal MVP stack is 3 vendors total:**

| Vendor | Services Used |
|--------|---------------|
| **Vercel** | Next.js 15.5 frontend + API routes |
| **Supabase** | Auth (phone OTP) + Postgres + Storage |
| **LiveKit Cloud** | Realtime rooms + **Managed Agent Hosting** |

**Critical insight you correctly identified:** LiveKit Cloud now offers managed agent hosting at $0.01/minute. This eliminates Fly.io entirely. Your agent deploys with `lk agent deploy` and runs on LiveKit's global infrastructure with auto-scaling, rolling deployments, and instant rollbacks.

---

## **Part 1: MVP Stack (Ship by Dec 3rd)**

### **Verified Versions (Nov 25, 2025)**

| Technology | Version | Source |
|------------|---------|--------|
| TypeScript | 5.9 | microsoft.com |
| Bun | 1.3.3 | bun.sh (released Nov 21) |
| Next.js | 15.5 | nextjs.org |
| React | 19 | stable since Dec 2024 |
| Zod | 4.x (`zod/v4`) | zod.dev (14x faster) |

### **MVP Architecture (3 Vendors)**

```
┌─────────────────────────────────────────────────────────────────┐
│                    Vercel (Next.js 15.5)                        │
│  ┌─────────────────┐     ┌─────────────────────────────────┐    │
│  │   React 19 UI   │────▶│  API Routes (Server Actions)    │    │
│  │   + Turbopack   │     │  - /api/livekit/token           │    │
│  └─────────────────┘     │  - /api/webhooks/livekit        │    │
│                          │  - /api/invites                 │    │
│                          └──────────────┬──────────────────┘    │
└─────────────────────────────────────────┼───────────────────────┘
                                          │
         ┌────────────────────────────────┼────────────────────────────┐
         ▼                                ▼                            │
┌─────────────────┐              ┌─────────────────┐                   │
│  Supabase       │              │  LiveKit Cloud  │                   │
│  ├─ Auth (OTP)  │              │  ├─ Rooms       │                   │
│  ├─ Postgres    │              │  ├─ Egress      │◀──────────────────┘
│  └─ Storage     │◀─────────────│  └─ Agent Host  │
└─────────────────┘   webhooks   └─────────────────┘
```

### **Why This Stack Fits Together**

**Supabase handles your entire data layer in one service.** Phone OTP auth via Twilio integration, Postgres database with Row Level Security, and S3-compatible storage for recordings. The `supabase-js` client provides authenticated database access directly from your Next.js API routes without separate connection management.

**LiveKit Cloud handles all realtime including your AI agent.** The agent deploys to LiveKit's infrastructure via `lk agent deploy`, and when a participant joins a room, LiveKit dispatches your agent automatically. No separate container hosting, no Fly.io, no Railway. LiveKit also handles recording via egress and sends webhooks to your `/api/webhooks/livekit` endpoint when recordings complete.

**Vercel handles your frontend and lightweight backend.** Next.js 15.5 with Turbopack provides fast development iteration. Your API routes are thin orchestration layers that validate with Zod, call Supabase for data, and mint LiveKit tokens. Server Actions can handle form submissions directly without explicit API routes.

### **Complete MVP Stack Table**

| Layer | Choice | Rationale |
|-------|--------|-----------|
| **Runtime** | Bun 1.3.3 | Native TS, 5-10x faster installs than pnpm, `bun test` is fast |
| **Language** | TypeScript 5.9 strict | Deferred type evaluation, eraseable syntax |
| **Schema** | Zod v4 (`import * as z from "zod/v4"`) | 14x faster parsing, tree-shakable via `zod/v4-mini` |
| **Frontend** | Next.js 15.5 + React 19 | Turbopack stable, Server Actions, App Router |
| **Styling** | Tailwind CSS 4 | CSS-first config, native cascade layers |
| **Database** | Supabase Postgres | Managed, phone auth integrated, RLS built-in |
| **Auth** | Supabase Auth (Phone OTP) | One vendor, Twilio integration, session management |
| **Storage** | Supabase Storage | S3-compatible, auth-aware policies, no egress fees |
| **Realtime** | LiveKit Cloud | Rooms, TURN servers, egress, agent hosting |
| **AI Agent** | LiveKit Cloud Agent Hosting | `lk agent deploy`, $0.01/min, auto-scale |
| **Deployment** | Vercel | Zero-config Next.js, edge functions, preview URLs |
| **Observability** | Vercel Analytics + Supabase Logs | Free tiers sufficient for MVP |

### **What You DON'T Need for MVP**

| Skip This | Why |
|-----------|-----|
| Fly.io / Railway | LiveKit Cloud hosts agents |
| Cloudflare R2 | Supabase Storage is sufficient |
| Separate Hono API | Next.js API routes are enough |
| Nx / Turborepo | Single app, no monorepo complexity needed |
| OpenTelemetry | Use Vercel/Supabase built-in logs first |
| Drizzle ORM | Supabase client is simpler for MVP |

---

## **Part 2: Forever Stack (Post-MVP Reference Menu)**

This is your reference for when specific scaling, compliance, or architectural needs arise. Each row indicates the trigger for upgrading from MVP to Forever stack.

### **Forever Stack Comparison Matrix**

| Layer | MVP Choice | Forever Choice | Trigger to Switch |
|-------|------------|----------------|-------------------|
| **Monorepo** | None (single Next.js app) | **Turborepo** or **Nx** | Multiple apps (mobile, admin), >3 engineers |
| **Package Mgr** | Bun | Bun (continue) | No change needed |
| **Database** | Supabase Postgres | **Neon** + **Drizzle ORM** | Need connection pooling control, multi-region, or 100k+ MAU |
| **Auth** | Supabase Auth | **Clerk** or **Auth0** | SSO requirements, enterprise compliance, SAML |
| **Storage** | Supabase Storage | **Cloudflare R2** | Free egress at scale, CDN integration |
| **API Layer** | Next.js API Routes | **HonoJS** on **Cloudflare Workers** | Separate deployments, multi-frontend, public API |
| **Background Jobs** | None | **Inngest** or **Trigger.dev** | Complex workflows, retries, scheduled tasks |
| **Queues** | None | **Cloudflare Queues** | High-volume event processing, decoupled services |
| **Observability** | Vercel + Supabase | **Honeycomb** + **OpenTelemetry** | Distributed tracing needs, custom metrics |
| **Agent Hosting** | LiveKit Cloud | **Self-hosted on K8s** | GPU requirements, custom scaling, cost optimization at scale |
| **Cache** | None | **Upstash Redis** | Session cache, rate limiting, real-time leaderboards |
| **Search** | None | **Meilisearch** or **Typesense** | Full-text search across recordings/transcripts |
| **CDN** | Vercel Edge | **Cloudflare** | Custom rules, WAF, DDoS protection |

### **When to Use Each Forever Stack Component**

**Neon + Drizzle** replaces Supabase Postgres when you need the serverless Postgres driver (`@neondatabase/serverless`) for edge deployments, or when you want SQL-first type-safe queries with explicit control over migrations. Drizzle's bundle size (50KB vs Prisma's 2MB) matters for Workers.

**HonoJS on Cloudflare Workers** replaces Next.js API routes when you need independent API deployments, sub-10ms cold starts, or when you're building a platform API for third parties. HonoJS's `@hono/zod-openapi` generates OpenAPI specs directly from your Zod schemas.

**Inngest** adds to your stack when you have multi-step workflows (e.g., "after recording completes, transcribe, then generate summary, then notify user"). It provides durable execution, automatic retries, and observability for background jobs.

**Cloudflare R2** replaces Supabase Storage when egress costs matter. R2 has zero egress fees. For LiveKit recordings at scale, this becomes significant.

---

## **Part 3: Implementation Checklist (Dec 3rd MVP)**

### **Day 1-2: Foundation**

1. Create Next.js 15.5 project with Bun:
   ```bash
   bunx create-next-app@latest ember --typescript --tailwind --app --turbo
   ```

2. Initialize Supabase project:
   - Enable Phone Auth with Twilio
   - Create tables: `users`, `persons`, `invites`, `sessions`, `recordings`
   - Set up RLS policies

3. Create LiveKit Cloud project:
   - Note API key and secret
   - Create agent with `lk agent init`

### **Day 3-4: Auth + Invites**

4. Implement phone OTP flow with `@supabase/ssr`

5. Create `/api/invites` route:
   - Validate with Zod v4
   - Generate unique invite token
   - Insert to Supabase
   - Return shareable URL

### **Day 5-6: LiveKit Integration**

6. Create `/api/livekit/token` route:
   - Verify invite is valid
   - Mint LiveKit access token with agent dispatch:
   ```typescript
   at.roomConfig = new RoomConfiguration({
     agents: [new RoomAgentDispatch({ agentName: "ember-agent" })]
   });
   ```

7. Deploy agent to LiveKit Cloud:
   ```bash
   lk agent deploy
   ```

### **Day 7-8: Recording + Playback**

8. Create `/api/webhooks/livekit` route:
   - Verify webhook signature
   - On `egress_ended`, update `recordings` table with file URL

9. Build listen page with audio player

### **Day 9: Polish + Launch**

10. End-to-end testing
11. Deploy to Vercel production

---

## **Success Metrics**

| Metric | Target | Measurement |
|--------|--------|-------------|
| Time to first OTP | <5 seconds | Manual testing |
| Agent join latency | <2 seconds | LiveKit dashboard |
| Recording availability | <30 seconds after call ends | Webhook → playback test |
| Vercel cold start | <100ms | Vercel analytics |

---

## **Next Action**

**Today:** Run `bunx create-next-app@latest ember --typescript --tailwind --app --turbo` and connect it to a new Supabase project. Verify phone OTP works with your Twilio credentials.

**Validation:** By EOD, you should receive an SMS OTP to your phone and see a logged-in session in Supabase Auth dashboard. If this works, your critical infrastructure is proven.



## Prompt:
11/25/2025, 12:01:42 PM

What is TurboPack and TurboRepo? I think long term, since I'm gonna fix it, I might need Python or Rust or WebAssembly, and just generally I don't like being tied to TypeScript only it will be the core part of this: the monorepo, the templates, the skeletons, and my frameworks. I do not really want Vercel stuff unless there is a good reason. I like their hosting and iterative capabilities and branching, but I do not like other stuff yet. I would prefer something simpler. Be specific and really think deeply around the front-end, the architecture, and the tech stack choices. I will freeze this for 90 days. Let's try to consolidate and make wise choices that prefer simplicity as the core and work reliably. Ideally, don't tie me to a provider vendor. Provide step-by-step instructions on how to set up this codebase.

And then after that provide a single LLM prompt one-shot that encodes all of these tech stack decisions and the intended architecture and workflows with exact specifications as detailed as possible to make sure it gets right and runs successfully and integrates successfully based off of environment variables at monorepo root.m file.m local file. To be clear, what I want is a specification that I will save as a document to the mon repo so I can use coding agents to use that as the source of truth and use that as the single source of truth going forward. Iterate on it and have that reflected into the codebase to Write this codebase comprehensively and completely.



## Response:
11/25/2025, 12:28:20 PM

````plaintext
Thought process: Architected vendor-agnostic polyglot stack prioritizing simplicity and independence.

The user is asking for several things:

1. Explanation of Turbopack vs Turborepo
2. A tech stack that:
   - Supports polyglot (Python, Rust, WebAssembly) not just TypeScript
   - Is NOT tied to Vercel tooling (though Vercel hosting is okay)
   - Prefers simplicity
   - Doesn't tie to a vendor
   - Will be frozen for 90 days
3. Step-by-step setup instructions for this codebase
4. A comprehensive LLM prompt/specification document that can be used as a source of truth for coding agents

Let me think deeply about this:

**Turbopack vs Turborepo:**
- Turbopack: A Rust-based bundler created by Vercel as a successor to Webpack. It's specifically for bundling JavaScript/TypeScript applications. It's integrated into Next.js.
- Turborepo: A monorepo build system for JavaScript/TypeScript projects. It handles task orchestration, caching, and parallel execution across packages in a monorepo.

**The user's concerns are valid:**
- They want polyglot support (Python, Rust, WASM)
- They don't want to be tied to Vercel-specific tooling
- They want simplicity and vendor independence

**For a polyglot monorepo, the options are:**
1. **Nx** - Supports multiple languages, has plugins for Python, Go, etc.
2. **Bazel** - Google's polyglot build system, complex but powerful
3. **Pants** - Python-first but supports multiple languages
4. **Just a simple workspace structure with Makefiles/Justfiles** - No magic, works with anything

Given the user's preference for simplicity and not being tied to vendors, I should recommend:
- **Simple workspace structure** with Bun workspaces for the TS parts
- **Just** or **Make** for orchestrating polyglot builds


- Avoiding Vercel-specific tools entirely

For frontend development, Vite + React offers a clean, vendor-agnostic solution that meets the simplicity requirement. It provides a lightweight, fast build system without locking into a specific ecosystem. The approach prioritizes flexibility and independence, allowing easy integration with various backend technologies and build tools.

Expanding the stack further, the focus remains on platforms that enable maximum portability and control. HonoJS emerges as a versatile API framework compatible with multiple runtimes. Neon Postgres with Drizzle ORM provides a robust, adaptable database solution. Cloudflare R2 ensures storage flexibility, while LiveKit Cloud handles real-time and agent hosting needs.

The core principle is building a stack that can seamlessly migrate between cloud providers and runtime environments, maintaining developer autonomy and system resilience. I'll focus on the specification document's comprehensive nature, emphasizing the need for precise documentation that captures architectural nuances and workflow details. The goal is creating a self-contained reference that enables autonomous agent implementation across different development environments. Key considerations include capturing intricate file organization principles, interaction patterns, and system design constraints that provide clear guidance for potential code generation scenarios.
````

# Understanding Turbopack, Turborepo, and Your Vendor-Agnostic Architecture

## TL;DR

**Turbopack and Turborepo are Vercel-specific tools that would lock you in.** For a polyglot monorepo that supports TypeScript, Python, Rust, and WASM while remaining vendor-agnostic, I recommend **Bun workspaces + Just** (a simple command runner). Your frontend should be **Vite + React** (not Next.js), deployable to Vercel or anywhere else. This gives you Vercel's preview/branching benefits without their tooling lock-in.

**Confidence: 95%** — This recommendation optimizes for your stated goals: simplicity, polyglot support, vendor independence, and 90-day freeze stability.

---

## Part 1: Turbopack vs Turborepo Explained

These are two distinct Vercel products that share the "Turbo" branding but serve completely different purposes.

**Turbopack** is a JavaScript/TypeScript bundler written in Rust. It takes your source files (React components, TypeScript modules, CSS) and bundles them into optimized files for the browser. Think of it as Vercel's replacement for Webpack. Turbopack is tightly integrated into Next.js and is not designed to work standalone. When you run `next dev --turbo`, you're using Turbopack. The key limitation for your use case is that Turbopack only understands JavaScript/TypeScript. It cannot bundle Python, Rust, or arbitrary polyglot code. It's a frontend build tool, not a monorepo orchestrator.

**Turborepo** is a monorepo build system that orchestrates tasks across multiple packages. It handles dependency graphs between packages, caches build outputs, and runs tasks in parallel. When you have packages A, B, and C where C depends on A and B, Turborepo figures out the correct build order and caches results so unchanged packages don't rebuild. However, Turborepo is designed primarily for JavaScript/TypeScript projects. While you can technically add Python or Rust packages, Turborepo doesn't understand their dependency graphs or build systems. You end up writing escape hatches that defeat the purpose.

**Why neither fits your requirements.** You want a monorepo that treats TypeScript, Python, and Rust as first-class citizens. You want to compile Rust to WASM and import it into your frontend. You want Python services that share protocol definitions with your TypeScript API. Turbopack cannot help here at all since it's purely a JS bundler. Turborepo could orchestrate the high-level tasks, but it adds complexity without providing value for non-JS languages. The simpler path is to use a language-agnostic task runner.

---

## Part 2: The Vendor-Agnostic Polyglot Stack

### Design Principles

Before presenting the stack, let me articulate the principles guiding these choices.

**Principle 1: Own the Build.** Your build system should be a thin orchestration layer over language-native tools. TypeScript uses `tsc` and `vite`. Rust uses `cargo`. Python uses `uv` or `pip`. A command runner like `just` or `make` ties them together without abstracting them away.

**Principle 2: Own the Data.** Your database schema, migrations, and data should be portable. Drizzle ORM generates standard SQL migrations that work on any Postgres. Your auth tokens are JWTs you control. Your files live in S3-compatible storage you can point anywhere.

**Principle 3: Own the Contracts.** Your API contracts should be defined in language-agnostic formats (OpenAPI, Protocol Buffers, or JSON Schema). Zod schemas can export to JSON Schema, which can generate types for Python (via `datamodel-code-generator`) or Rust (via `typify`).

**Principle 4: Minimize Vendor Surface.** Every vendor integration should be behind an abstraction you control. LiveKit is your realtime layer, but your code calls your own `RealtimeClient` interface. Switching vendors means implementing that interface differently, not rewriting your app.

### The Revised Stack

| Layer | Choice | Rationale |
|-------|--------|-----------|
| **Monorepo** | Bun workspaces + Just | Language-agnostic task running, no JS-specific magic |
| **Language (Primary)** | TypeScript 5.9 strict | Your core apps, validated by Zod v4 |
| **Language (Extensions)** | Python 3.12, Rust 1.83 | For ML/AI agents, performance-critical WASM |
| **Schema Validation** | Zod v4 → JSON Schema | Contracts exportable to any language |
| **Frontend** | Vite 6 + React 19 | No framework lock-in, deploys anywhere |
| **API** | HonoJS 4.x | Runs on Bun, Node, Deno, or Workers |
| **Database** | Neon Postgres + Drizzle | Serverless Postgres, SQL-first ORM |
| **Auth** | BetterAuth | Self-hosted, no vendor dependency |
| **Storage** | Cloudflare R2 | S3-compatible, zero egress, swappable |
| **Realtime** | LiveKit Cloud | Agent hosting included, SDK is open-source |
| **Hosting (Frontend)** | Vercel | Preview URLs, but app is portable |
| **Hosting (API)** | Cloudflare Workers or Fly.io | Edge or container, your choice |
| **Observability** | OpenTelemetry → Honeycomb | Vendor-neutral telemetry protocol |

### Why Vite + React Instead of Next.js

Next.js bundles framework opinions (file-based routing, server components, caching semantics) with hosting optimizations (ISR, edge middleware) in ways that work best on Vercel. You can deploy Next.js elsewhere, but you lose features or fight configuration. More importantly, Next.js is evolving rapidly with breaking changes between minor versions, which conflicts with your 90-day freeze goal.

Vite + React is simpler. Vite is a build tool that uses native ES modules in development and Rollup for production builds. React is the UI library. There's no magic routing, no server components, no vendor-specific features. Your Vite app builds to a `dist/` folder containing static HTML, JS, and CSS that deploys to any static host or CDN.

For routing, you add `react-router-dom` or `@tanstack/router`. For data fetching, you use `@tanstack/query`. These are explicit dependencies you control, not framework internals that might change.

### Why HonoJS for the API

HonoJS is a small, fast web framework that runs on any JavaScript runtime. The same code works on Bun, Node.js, Deno, and Cloudflare Workers without modification. This means you can develop locally with Bun, deploy to Workers for edge performance, or deploy to a container on Fly.io if you need longer execution times. You're not locked into any runtime or platform.

HonoJS has excellent Zod integration via `@hono/zod-openapi`, which generates OpenAPI specs from your route definitions. This spec becomes the contract that other languages can consume.

### Why BetterAuth Instead of Supabase Auth or Clerk

BetterAuth is a self-hosted authentication library, not a service. You bring your own database (your Neon Postgres) and your own SMS provider (Twilio). The authentication logic runs in your API, generating JWTs you control. If you later want to switch to a different auth approach, you're migrating code, not extracting data from a vendor's proprietary system.

Supabase Auth is excellent but couples you to Supabase's session management. Clerk is polished but is a separate vendor with its own pricing and data residency concerns. BetterAuth keeps auth as code you own.

---

## Part 3: Monorepo Structure

```
ember/
├── .env.local                    # Local environment variables (gitignored)
├── .env.example                  # Template for required env vars
├── justfile                      # Task runner commands
├── bun.lockb                     # Bun lockfile
├── package.json                  # Root workspace config
├── tsconfig.base.json            # Shared TypeScript config
├── biome.json                    # Linting and formatting
├── ARCHITECTURE.md               # The specification document (created below)
│
├── apps/
│   ├── web/                      # Vite + React frontend
│   │   ├── package.json
│   │   ├── vite.config.ts
│   │   ├── index.html
│   │   └── src/
│   │       ├── main.tsx
│   │       ├── routes/
│   │       └── components/
│   │
│   ├── api/                      # HonoJS API server
│   │   ├── package.json
│   │   ├── src/
│   │   │   ├── index.ts          # Entry point
│   │   │   ├── routes/           # Route handlers
│   │   │   ├── middleware/       # Auth, logging, etc.
│   │   │   └── lib/              # Business logic
│   │   └── wrangler.toml         # Cloudflare Workers config (optional)
│   │
│   └── agent/                    # LiveKit AI agent (Python or Node)
│       ├── pyproject.toml        # If Python
│       ├── package.json          # If Node
│       ├── livekit.toml          # LiveKit Cloud config
│       └── src/
│
├── packages/
│   ├── contracts/                # Shared schemas and types
│   │   ├── package.json
│   │   └── src/
│   │       ├── schemas/          # Zod schemas
│   │       ├── generated/        # JSON Schema, OpenAPI
│   │       └── index.ts
│   │
│   ├── db/                       # Drizzle schema and migrations
│   │   ├── package.json
│   │   ├── drizzle.config.ts
│   │   └── src/
│   │       ├── schema.ts
│   │       ├── migrations/
│   │       └── index.ts
│   │
│   └── ui/                       # Shared React components (optional)
│       ├── package.json
│       └── src/
│
└── tools/                        # Build scripts, codegen
    ├── generate-openapi.ts       # Zod → OpenAPI
    └── generate-python-types.ts  # JSON Schema → Python dataclasses
```

### Why This Structure

The `apps/` directory contains deployable units. Each app has its own `package.json`, its own build process, and deploys independently. The `web` app knows nothing about `api` internals; it only knows the API contract.

The `packages/` directory contains shared code. The `contracts` package is the single source of truth for data shapes. The `db` package is the single source of truth for database schema. These are internal packages consumed by apps via Bun workspace links.

The `tools/` directory contains build-time scripts that generate artifacts. The `generate-openapi.ts` script reads Zod schemas and produces an OpenAPI spec. The `generate-python-types.ts` script reads that spec and produces Python dataclasses for the agent.

This structure supports polyglot because each app can use its own language. The `agent` folder can be Python with `pyproject.toml`. The contract between TypeScript and Python is the generated JSON Schema or OpenAPI spec, not shared source code.

---

## Part 4: Step-by-Step Setup Instructions

### Prerequisites

Ensure you have the following installed:

```bash
# Bun (JavaScript runtime and package manager)
curl -fsSL https://bun.sh/install | bash

# Just (command runner)
# macOS
brew install just
# or via cargo
cargo install just

# Python 3.12+ with uv (fast Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Rust (if using WASM later)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# LiveKit CLI
brew install livekit-cli
# or
curl -sSL https://get.livekit.io/cli | bash
```

### Step 1: Initialize the Monorepo

```bash
# Create root directory
mkdir ember && cd ember

# Initialize Bun workspace
bun init -y

# Create workspace structure
mkdir -p apps/web apps/api apps/agent
mkdir -p packages/contracts packages/db
mkdir -p tools
```

Create `package.json` at root:

```json
{
  "name": "ember",
  "private": true,
  "workspaces": ["apps/*", "packages/*"],
  "scripts": {
    "dev": "just dev",
    "build": "just build",
    "test": "just test",
    "typecheck": "just typecheck"
  },
  "devDependencies": {
    "@biomejs/biome": "^1.9.4",
    "typescript": "^5.9.0-dev.20251120"
  }
}
```

Create `tsconfig.base.json`:

```json
{
  "compilerOptions": {
    "target": "ES2024",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "strict": true,
    "noEmit": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "verbatimModuleSyntax": true,
    "lib": ["ES2024", "DOM", "DOM.Iterable"],
    "types": ["bun-types"]
  }
}
```

Create `biome.json`:

```json
{
  "$schema": "https://biomejs.dev/schemas/1.9.4/schema.json",
  "organizeImports": { "enabled": true },
  "linter": {
    "enabled": true,
    "rules": { "recommended": true }
  },
  "formatter": {
    "enabled": true,
    "indentStyle": "space",
    "indentWidth": 2
  }
}
```

Create `justfile`:

```makefile
# Default recipe: show available commands
default:
    @just --list

# Install all dependencies
install:
    bun install
    cd apps/agent && uv sync

# Run all apps in development mode
dev:
    just dev-web & just dev-api & wait

# Run web app
dev-web:
    cd apps/web && bun run dev

# Run API server
dev-api:
    cd apps/api && bun run dev

# Run agent locally
dev-agent:
    cd apps/agent && uv run python -m agent

# Build all apps
build:
    just build-contracts
    just build-web
    just build-api

# Build contracts (generate OpenAPI, JSON Schema)
build-contracts:
    cd packages/contracts && bun run build

# Build web app
build-web:
    cd apps/web && bun run build

# Build API
build-api:
    cd apps/api && bun run build

# Run all tests
test:
    bun test

# Type check all TypeScript
typecheck:
    bun run --filter '*' typecheck

# Generate database migrations
db-generate:
    cd packages/db && bun run drizzle-kit generate

# Push migrations to database
db-push:
    cd packages/db && bun run drizzle-kit push

# Deploy agent to LiveKit Cloud
deploy-agent:
    cd apps/agent && lk agent deploy

# Format all code
fmt:
    bunx biome format --write .
    cd apps/agent && uv run ruff format .

# Lint all code
lint:
    bunx biome lint .
    cd apps/agent && uv run ruff check .
```

### Step 2: Set Up the Contracts Package

```bash
cd packages/contracts
bun init -y
```

Edit `packages/contracts/package.json`:

```json
{
  "name": "@ember/contracts",
  "version": "0.0.1",
  "private": true,
  "type": "module",
  "exports": {
    ".": "./src/index.ts",
    "./schemas": "./src/schemas/index.ts"
  },
  "scripts": {
    "build": "bun run ./scripts/generate.ts",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "zod": "^3.25.0"
  },
  "devDependencies": {
    "typescript": "^5.9.0-dev.20251120"
  }
}
```

Create `packages/contracts/tsconfig.json`:

```json
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "rootDir": "src",
    "outDir": "dist"
  },
  "include": ["src/**/*"]
}
```

Create `packages/contracts/src/schemas/index.ts`:

```typescript
// Core domain schemas - the single source of truth
import * as z from "zod/v4";

// ============================================================
// User & Person Schemas
// ============================================================

export const UserIdSchema = z.string().uuid();
export const PhoneSchema = z.string().regex(/^\+[1-9]\d{1,14}$/);

export const UserSchema = z.object({
  id: UserIdSchema,
  phone: PhoneSchema,
  createdAt: z.iso.datetime(),
  updatedAt: z.iso.datetime(),
});

export const PersonSchema = z.object({
  id: z.string().uuid(),
  userId: UserIdSchema,
  name: z.string().min(1).max(100),
  relationship: z.enum(["parent", "grandparent", "other"]),
  phone: PhoneSchema.optional(),
  createdAt: z.iso.datetime(),
});

// ============================================================
// Invite Schemas
// ============================================================

export const InviteStatusSchema = z.enum([
  "pending",
  "accepted",
  "expired",
  "revoked",
]);

export const InviteSchema = z.object({
  id: z.string().uuid(),
  token: z.string().length(32),
  creatorId: UserIdSchema,
  personId: z.string().uuid(),
  status: InviteStatusSchema,
  expiresAt: z.iso.datetime(),
  createdAt: z.iso.datetime(),
});

export const CreateInviteRequestSchema = z.object({
  personName: z.string().min(1).max(100),
  personPhone: PhoneSchema.optional(),
  relationship: z.enum(["parent", "grandparent", "other"]),
});

export const CreateInviteResponseSchema = z.object({
  inviteId: z.string().uuid(),
  inviteUrl: z.string().url(),
  expiresAt: z.iso.datetime(),
});

// ============================================================
// Session & Recording Schemas
// ============================================================

export const SessionStatusSchema = z.enum([
  "waiting",
  "active",
  "completed",
  "failed",
]);

export const SessionSchema = z.object({
  id: z.string().uuid(),
  inviteId: z.string().uuid(),
  roomName: z.string(),
  status: SessionStatusSchema,
  startedAt: z.iso.datetime().optional(),
  endedAt: z.iso.datetime().optional(),
  createdAt: z.iso.datetime(),
});

export const RecordingSchema = z.object({
  id: z.string().uuid(),
  sessionId: z.string().uuid(),
  storageKey: z.string(),
  durationSeconds: z.number().int().positive(),
  sizeBytes: z.number().int().positive(),
  createdAt: z.iso.datetime(),
});

// ============================================================
// LiveKit Token Request
// ============================================================

export const LiveKitTokenRequestSchema = z.object({
  inviteToken: z.string().length(32),
});

export const LiveKitTokenResponseSchema = z.object({
  token: z.string(),
  roomName: z.string(),
  serverUrl: z.string().url(),
});

// ============================================================
// Type Exports
// ============================================================

export type User = z.infer<typeof UserSchema>;
export type Person = z.infer<typeof PersonSchema>;
export type Invite = z.infer<typeof InviteSchema>;
export type CreateInviteRequest = z.infer<typeof CreateInviteRequestSchema>;
export type CreateInviteResponse = z.infer<typeof CreateInviteResponseSchema>;
export type Session = z.infer<typeof SessionSchema>;
export type Recording = z.infer<typeof RecordingSchema>;
export type LiveKitTokenRequest = z.infer<typeof LiveKitTokenRequestSchema>;
export type LiveKitTokenResponse = z.infer<typeof LiveKitTokenResponseSchema>;
```

Create `packages/contracts/src/index.ts`:

```typescript
export * from "./schemas/index.js";
```

Create `packages/contracts/scripts/generate.ts`:

```typescript
// Generates JSON Schema and OpenAPI from Zod schemas
import * as z from "zod/v4";
import { writeFileSync, mkdirSync } from "node:fs";
import * as schemas from "../src/schemas/index.js";

// Ensure output directory exists
mkdirSync("./src/generated", { recursive: true });

// Generate JSON Schema for each schema
const jsonSchemas: Record<string, unknown> = {};
for (const [name, schema] of Object.entries(schemas)) {
  if (name.endsWith("Schema") && schema instanceof z.ZodType) {
    const jsonSchema = z.toJSONSchema(schema, { target: "draft-2020-12" });
    jsonSchemas[name.replace("Schema", "")] = jsonSchema;
  }
}

writeFileSync(
  "./src/generated/schemas.json",
  JSON.stringify(jsonSchemas, null, 2)
);

console.log("✓ Generated JSON Schemas");
```

### Step 3: Set Up the Database Package

```bash
cd packages/db
bun init -y
bun add drizzle-orm @neondatabase/serverless
bun add -d drizzle-kit
```

Edit `packages/db/package.json`:

```json
{
  "name": "@ember/db",
  "version": "0.0.1",
  "private": true,
  "type": "module",
  "exports": {
    ".": "./src/index.ts",
    "./schema": "./src/schema.ts"
  },
  "scripts": {
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "@neondatabase/serverless": "^0.10.4",
    "drizzle-orm": "^0.38.3"
  },
  "devDependencies": {
    "drizzle-kit": "^0.30.1",
    "typescript": "^5.9.0-dev.20251120"
  }
}
```

Create `packages/db/src/schema.ts`:

```typescript
import {
  pgTable,
  uuid,
  varchar,
  timestamp,
  text,
  integer,
  bigint,
} from "drizzle-orm/pg-core";

export const users = pgTable("users", {
  id: uuid("id").primaryKey().defaultRandom(),
  phone: varchar("phone", { length: 20 }).notNull().unique(),
  createdAt: timestamp("created_at", { withTimezone: true })
    .notNull()
    .defaultNow(),
  updatedAt: timestamp("updated_at", { withTimezone: true })
    .notNull()
    .defaultNow(),
});

export const persons = pgTable("persons", {
  id: uuid("id").primaryKey().defaultRandom(),
  userId: uuid("user_id")
    .notNull()
    .references(() => users.id),
  name: varchar("name", { length: 100 }).notNull(),
  relationship: varchar("relationship", { length: 20 }).notNull(),
  phone: varchar("phone", { length: 20 }),
  createdAt: timestamp("created_at", { withTimezone: true })
    .notNull()
    .defaultNow(),
});

export const invites = pgTable("invites", {
  id: uuid("id").primaryKey().defaultRandom(),
  token: varchar("token", { length: 32 }).notNull().unique(),
  creatorId: uuid("creator_id")
    .notNull()
    .references(() => users.id),
  personId: uuid("person_id")
    .notNull()
    .references(() => persons.id),
  status: varchar("status", { length: 20 }).notNull().default("pending"),
  expiresAt: timestamp("expires_at", { withTimezone: true }).notNull(),
  createdAt: timestamp("created_at", { withTimezone: true })
    .notNull()
    .defaultNow(),
});

export const sessions = pgTable("sessions", {
  id: uuid("id").primaryKey().defaultRandom(),
  inviteId: uuid("invite_id")
    .notNull()
    .references(() => invites.id),
  roomName: varchar("room_name", { length: 100 }).notNull(),
  status: varchar("status", { length: 20 }).notNull().default("waiting"),
  startedAt: timestamp("started_at", { withTimezone: true }),
  endedAt: timestamp("ended_at", { withTimezone: true }),
  createdAt: timestamp("created_at", { withTimezone: true })
    .notNull()
    .defaultNow(),
});

export const recordings = pgTable("recordings", {
  id: uuid("id").primaryKey().defaultRandom(),
  sessionId: uuid("session_id")
    .notNull()
    .references(() => sessions.id),
  storageKey: text("storage_key").notNull(),
  durationSeconds: integer("duration_seconds").notNull(),
  sizeBytes: bigint("size_bytes", { mode: "number" }).notNull(),
  createdAt: timestamp("created_at", { withTimezone: true })
    .notNull()
    .defaultNow(),
});
```

Create `packages/db/src/index.ts`:

```typescript
import { neon } from "@neondatabase/serverless";
import { drizzle } from "drizzle-orm/neon-http";
import * as schema from "./schema.js";

export function createDb(databaseUrl: string) {
  const sql = neon(databaseUrl);
  return drizzle(sql, { schema });
}

export * from "./schema.js";
export type Database = ReturnType<typeof createDb>;
```

Create `packages/db/drizzle.config.ts`:

```typescript
import { defineConfig } from "drizzle-kit";

export default defineConfig({
  schema: "./src/schema.ts",
  out: "./src/migrations",
  dialect: "postgresql",
  dbCredentials: {
    url: process.env.DATABASE_URL!,
  },
});
```

### Step 4: Set Up the Web App (Vite + React)

```bash
cd apps/web
bun create vite . --template react-ts
bun add @tanstack/react-router @tanstack/react-query
bun add -d @tanstack/router-plugin @tanstack/router-devtools
```

Edit `apps/web/package.json`:

```json
{
  "name": "@ember/web",
  "version": "0.0.1",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc -b && vite build",
    "preview": "vite preview",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "@ember/contracts": "workspace:*",
    "@tanstack/react-query": "^5.62.8",
    "@tanstack/react-router": "^1.93.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  },
  "devDependencies": {
    "@tanstack/router-devtools": "^1.93.1",
    "@tanstack/router-plugin": "^1.93.1",
    "@types/react": "^19.0.2",
    "@types/react-dom": "^19.0.2",
    "@vitejs/plugin-react": "^4.3.4",
    "typescript": "^5.9.0-dev.20251120",
    "vite": "^6.0.3"
  }
}
```

Create `apps/web/vite.config.ts`:

```typescript
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import { TanStackRouterVite } from "@tanstack/router-plugin/vite";

export default defineConfig({
  plugins: [TanStackRouterVite(), react()],
  server: {
    port: 3000,
    proxy: {
      "/api": {
        target: "http://localhost:8787",
        changeOrigin: true,
      },
    },
  },
});
```

### Step 5: Set Up the API (HonoJS)

```bash
cd apps/api
bun init -y
bun add hono @hono/zod-openapi
bun add @ember/contracts @ember/db
bun add better-auth livekit-server-sdk @livekit/protocol
```

Edit `apps/api/package.json`:

```json
{
  "name": "@ember/api",
  "version": "0.0.1",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "bun run --hot src/index.ts",
    "build": "bun build src/index.ts --outdir dist --target bun",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "@ember/contracts": "workspace:*",
    "@ember/db": "workspace:*",
    "@hono/zod-openapi": "^0.18.3",
    "@livekit/protocol": "^1.31.0",
    "better-auth": "^1.1.10",
    "hono": "^4.6.14",
    "livekit-server-sdk": "^2.9.1"
  },
  "devDependencies": {
    "typescript": "^5.9.0-dev.20251120"
  }
}
```

Create `apps/api/src/index.ts`:

```typescript
import { Hono } from "hono";
import { cors } from "hono/cors";
import { logger } from "hono/logger";
import { createDb } from "@ember/db";
import { invitesRouter } from "./routes/invites.js";
import { livekitRouter } from "./routes/livekit.js";
import { webhooksRouter } from "./routes/webhooks.js";

// Environment type
type Env = {
  DATABASE_URL: string;
  LIVEKIT_API_KEY: string;
  LIVEKIT_API_SECRET: string;
  LIVEKIT_URL: string;
  R2_ACCESS_KEY_ID: string;
  R2_SECRET_ACCESS_KEY: string;
  R2_BUCKET: string;
  R2_ENDPOINT: string;
};

const app = new Hono<{ Bindings: Env }>();

// Middleware
app.use("*", logger());
app.use(
  "*",
  cors({
    origin: ["http://localhost:3000"],
    credentials: true,
  })
);

// Health check
app.get("/health", (c) => c.json({ status: "ok" }));

// Mount routers
app.route("/api/invites", invitesRouter);
app.route("/api/livekit", livekitRouter);
app.route("/api/webhooks", webhooksRouter);

// Start server
const port = parseInt(process.env.PORT || "8787");
console.log(`🚀 API server running on http://localhost:${port}`);

export default {
  port,
  fetch: app.fetch,
};
```

Create `apps/api/src/routes/invites.ts`:

```typescript
import { Hono } from "hono";
import { zValidator } from "@hono/zod-validator";
import { CreateInviteRequestSchema } from "@ember/contracts";
import { createDb, invites, persons } from "@ember/db";
import { randomBytes } from "node:crypto";

type Env = {
  DATABASE_URL: string;
};

export const invitesRouter = new Hono<{ Bindings: Env }>();

invitesRouter.post(
  "/",
  zValidator("json", CreateInviteRequestSchema),
  async (c) => {
    const body = c.req.valid("json");
    const db = createDb(c.env.DATABASE_URL);

    // Generate unique token
    const token = randomBytes(16).toString("hex");

    // Create person and invite in transaction
    // (simplified - add proper transaction handling)
    const [person] = await db
      .insert(persons)
      .values({
        userId: "TODO_FROM_AUTH", // Get from auth context
        name: body.personName,
        relationship: body.relationship,
        phone: body.personPhone,
      })
      .returning();

    const expiresAt = new Date();
    expiresAt.setDate(expiresAt.getDate() + 7); // 7 day expiry

    const [invite] = await db
      .insert(invites)
      .values({
        token,
        creatorId: "TODO_FROM_AUTH",
        personId: person.id,
        expiresAt,
      })
      .returning();

    const baseUrl = process.env.APP_URL || "http://localhost:3000";

    return c.json({
      inviteId: invite.id,
      inviteUrl: `${baseUrl}/invite/${token}`,
      expiresAt: invite.expiresAt.toISOString(),
    });
  }
);
```

Create `apps/api/src/routes/livekit.ts`:

```typescript
import { Hono } from "hono";
import { zValidator } from "@hono/zod-validator";
import { LiveKitTokenRequestSchema } from "@ember/contracts";
import { AccessToken, VideoGrant } from "livekit-server-sdk";
import { RoomConfiguration, RoomAgentDispatch } from "@livekit/protocol";
import { createDb, invites, sessions } from "@ember/db";
import { eq } from "drizzle-orm";

type Env = {
  DATABASE_URL: string;
  LIVEKIT_API_KEY: string;
  LIVEKIT_API_SECRET: string;
  LIVEKIT_URL: string;
};

export const livekitRouter = new Hono<{ Bindings: Env }>();

livekitRouter.post(
  "/token",
  zValidator("json", LiveKitTokenRequestSchema),
  async (c) => {
    const { inviteToken } = c.req.valid("json");
    const db = createDb(c.env.DATABASE_URL);

    // Validate invite
    const [invite] = await db
      .select()
      .from(invites)
      .where(eq(invites.token, inviteToken))
      .limit(1);

    if (!invite || invite.status !== "pending") {
      return c.json({ error: "Invalid or expired invite" }, 400);
    }

    if (new Date() > invite.expiresAt) {
      return c.json({ error: "Invite has expired" }, 400);
    }

    // Create room name
    const roomName = `ember-${invite.id}`;

    // Create session record
    await db.insert(sessions).values({
      inviteId: invite.id,
      roomName,
      status: "waiting",
    });

    // Generate LiveKit token with agent dispatch
    const at = new AccessToken(
      c.env.LIVEKIT_API_KEY,
      c.env.LIVEKIT_API_SECRET,
      {
        identity: `participant-${invite.personId}`,
        name: "Participant",
      }
    );

    const videoGrant: VideoGrant = {
      room: roomName,
      roomJoin: true,
      canPublish: true,
      canSubscribe: true,
    };

    at.addGrant(videoGrant);

    // Dispatch agent when participant joins
    at.roomConfig = new RoomConfiguration({
      agents: [
        new RoomAgentDispatch({
          agentName: "ember-agent",
          metadata: JSON.stringify({
            inviteId: invite.id,
            personId: invite.personId,
          }),
        }),
      ],
    });

    const token = await at.toJwt();

    return c.json({
      token,
      roomName,
      serverUrl: c.env.LIVEKIT_URL,
    });
  }
);
```

### Step 6: Set Up the Agent (Python with LiveKit)

```bash
cd apps/agent
```

Create `apps/agent/pyproject.toml`:

```toml
[project]
name = "ember-agent"
version = "0.1.0"
description = "Ember voice AI agent"
requires-python = ">=3.12"
dependencies = [
    "livekit-agents>=0.12.0",
    "livekit-plugins-openai>=0.10.0",
    "livekit-plugins-silero>=0.7.0",
    "python-dotenv>=1.0.0",
]

[tool.uv]
dev-dependencies = [
    "ruff>=0.8.0",
    "mypy>=1.13.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

Create `apps/agent/livekit.toml`:

```toml
[agent]
name = "ember-agent"

[build]
dockerfile = "Dockerfile"

[secrets]
OPENAI_API_KEY = ""
```

Create `apps/agent/src/__init__.py`:

```python
"""Ember voice AI agent."""
```

Create `apps/agent/src/agent.py`:

```python
"""Main agent implementation."""

import json
import logging
from livekit import agents, rtc
from livekit.agents import JobContext, WorkerOptions, cli
from livekit.agents.voice import VoiceAgent
from livekit.plugins import openai, silero

logger = logging.getLogger("ember-agent")


async def entrypoint(ctx: JobContext):
    """Main entrypoint for the agent."""
    logger.info(f"Agent started for room: {ctx.room.name}")
    
    # Parse metadata from dispatch
    metadata = {}
    if ctx.job.agent_dispatch and ctx.job.agent_dispatch.metadata:
        metadata = json.loads(ctx.job.agent_dispatch.metadata)
    
    invite_id = metadata.get("inviteId", "unknown")
    person_id = metadata.get("personId", "unknown")
    
    logger.info(f"Serving invite {invite_id} for person {person_id}")

    # Connect to the room
    await ctx.connect()

    # Wait for first participant
    participant = await ctx.wait_for_participant()
    logger.info(f"Participant joined: {participant.identity}")

    # Create the voice agent
    agent = VoiceAgent(
        vad=silero.VAD.load(),
        stt=openai.STT(),
        llm=openai.LLM(model="gpt-4o"),
        tts=openai.TTS(voice="alloy"),
        chat_ctx=agents.ChatContext(
            messages=[
                agents.ChatMessage(
                    role="system",
                    content="""You are a warm, patient interviewer helping someone 
                    record memories and stories for their family. Ask open-ended 
                    questions about their life experiences, memories, and wisdom 
                    they want to share. Be encouraging and help them feel 
                    comfortable sharing. Keep your responses brief to let them 
                    do most of the talking.""",
                )
            ]
        ),
    )

    # Start the conversation
    agent.start(ctx.room, participant)

    # Keep running until the participant leaves
    await agent.say("Hello! I'm so glad you're here to share your stories. What memory would you like to start with today?")


if __name__ == "__main__":
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))
```

Create `apps/agent/Dockerfile`:

```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Install uv
RUN pip install uv

# Copy project files
COPY pyproject.toml .
COPY src/ src/

# Install dependencies
RUN uv sync --frozen

# Run the agent
CMD ["uv", "run", "python", "-m", "src.agent"]
```

### Step 7: Create Environment Configuration

Create `.env.example` at root:

```bash
# Database (Neon)
DATABASE_URL=postgresql://user:pass@host.neon.tech/ember?sslmode=require

# LiveKit
LIVEKIT_API_KEY=your_api_key
LIVEKIT_API_SECRET=your_api_secret
LIVEKIT_URL=wss://your-project.livekit.cloud

# Cloudflare R2 Storage
R2_ACCESS_KEY_ID=your_access_key
R2_SECRET_ACCESS_KEY=your_secret_key
R2_BUCKET=ember-recordings
R2_ENDPOINT=https://your-account.r2.cloudflarestorage.com

# OpenAI (for agent)
OPENAI_API_KEY=sk-your-key

# Twilio (for SMS/phone auth)
TWILIO_ACCOUNT_SID=your_sid
TWILIO_AUTH_TOKEN=your_token
TWILIO_PHONE_NUMBER=+1234567890

# App
APP_URL=http://localhost:3000
```

### Step 8: Install and Verify

```bash
# From root directory
bun install

# Generate contracts
just build-contracts

# Generate database migrations
just db-generate

# Create .env.local from .env.example and fill in values
cp .env.example .env.local

# Push migrations to database
just db-push

# Run development servers
just dev
```

---

## Part 5: The Architecture Specification Document

This document should be saved as `ARCHITECTURE.md` at the root of your monorepo. It serves as the single source of truth for coding agents and future development.

```markdown
# Ember Architecture Specification

Version: 1.0.0
Last Updated: 2025-11-25
Freeze Until: 2025-02-25 (90 days)

## Executive Summary

Ember is a voice memory platform where children invite parents/grandparents to record stories with an AI interviewer. This document specifies the complete technical architecture, technology choices, and implementation patterns. It is the authoritative reference for all development work.

## Core Principles

1. **Own the Build**: Language-native tools orchestrated by Just, not framework magic.
2. **Own the Data**: Portable Postgres schemas, JWT auth tokens, S3-compatible storage.
3. **Own the Contracts**: Zod schemas export to JSON Schema for polyglot type generation.
4. **Minimize Vendor Surface**: Every vendor behind an abstraction we control.

## Technology Stack (Frozen)

### Versions (Locked)

| Technology | Version | Lock Reason |
|------------|---------|-------------|
| TypeScript | 5.9.x | Stable, eraseable syntax support |
| Bun | 1.3.x | Runtime and package manager |
| React | 19.x | Concurrent features stable |
| Vite | 6.x | Build tool, no bundler lock-in |
| HonoJS | 4.x | Multi-runtime web framework |
| Drizzle ORM | 0.38.x | SQL-first, edge-compatible |
| Zod | 4.x (via zod/v4) | 14x faster, JSON Schema export |
| Python | 3.12.x | Agent runtime |
| LiveKit Agents | 0.12.x | Voice AI framework |

### Infrastructure

| Service | Provider | Purpose | Portability |
|---------|----------|---------|-------------|
| Database | Neon | Serverless Postgres | Any Postgres |
| Auth | BetterAuth | Self-hosted JWT | Any JWT library |
| Storage | Cloudflare R2 | S3-compatible blobs | Any S3 |
| Realtime | LiveKit Cloud | WebRTC rooms + agents | Self-hosted LiveKit |
| Frontend Hosting | Vercel | Static + preview URLs | Any static host |
| API Hosting | Cloudflare Workers | Edge compute | Bun/Node anywhere |

## Directory Structure

```
ember/
├── .env.local              # Environment variables (gitignored)
├── .env.example            # Template for required variables
├── justfile                # Task runner commands
├── package.json            # Bun workspace root
├── tsconfig.base.json      # Shared TypeScript configuration
├── biome.json              # Linting and formatting rules
├── ARCHITECTURE.md         # This document
│
├── apps/
│   ├── web/                # React + Vite frontend
│   │   ├── package.json
│   │   ├── vite.config.ts
│   │   ├── tsconfig.json
│   │   ├── index.html
│   │   └── src/
│   │       ├── main.tsx           # App entry point
│   │       ├── routeTree.gen.ts   # Generated by TanStack Router
│   │       ├── routes/            # File-based routes
│   │       │   ├── __root.tsx     # Root layout
│   │       │   ├── index.tsx      # Home page
│   │       │   ├── invite.$token.tsx  # Invite landing
│   │       │   └── listen.$sessionId.tsx
│   │       ├── components/        # Shared React components
│   │       ├── hooks/             # Custom React hooks
│   │       └── lib/               # Utilities
│   │           ├── api.ts         # API client
│   │           └── livekit.ts     # LiveKit client wrapper
│   │
│   ├── api/                # HonoJS API server
│   │   ├── package.json
│   │   ├── tsconfig.json
│   │   ├── wrangler.toml   # Cloudflare Workers config
│   │   └── src/
│   │       ├── index.ts           # App entry, middleware setup
│   │       ├── routes/
│   │       │   ├── auth.ts        # Phone OTP endpoints
│   │       │   ├── invites.ts     # Invite CRUD
│   │       │   ├── livekit.ts     # Token generation
│   │       │   ├── recordings.ts  # Signed URLs
│   │       │   └── webhooks.ts    # LiveKit callbacks
│   │       ├── middleware/
│   │       │   ├── auth.ts        # JWT verification
│   │       │   └── db.ts          # Database connection
│   │       └── lib/
│   │           ├── auth.ts        # BetterAuth config
│   │           ├── livekit.ts     # Token generation
│   │           └── storage.ts     # R2 client
│   │
│   └── agent/              # Python LiveKit agent
│       ├── pyproject.toml
│       ├── livekit.toml
│       ├── Dockerfile
│       └── src/
│           ├── __init__.py
│           ├── agent.py           # Main agent entrypoint
│           ├── prompts.py         # System prompts
│           └── config.py          # Environment config
│
├── packages/
│   ├── contracts/          # Shared schemas (source of truth)
│   │   ├── package.json
│   │   ├── tsconfig.json
│   │   └── src/
│   │       ├── schemas/
│   │       │   ├── user.ts
│   │       │   ├── invite.ts
│   │       │   ├── session.ts
│   │       │   └── index.ts       # Barrel export
│   │       ├── generated/
│   │       │   └── schemas.json   # JSON Schema output
│   │       └── index.ts
│   │
│   └── db/                 # Database schema and client
│       ├── package.json
│       ├── tsconfig.json
│       ├── drizzle.config.ts
│       └── src/
│           ├── schema.ts         # Drizzle table definitions
│           ├── migrations/       # SQL migration files
│           └── index.ts          # Client factory
│
└── tools/
    ├── generate-openapi.ts
    └── generate-python-types.ts
```

## Data Model

### Entity Relationship

```
User 1──* Person 1──* Invite 1──1 Session 1──* Recording
```

### Tables

#### users
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| phone | VARCHAR(20) | UNIQUE, NOT NULL |
| created_at | TIMESTAMPTZ | NOT NULL, default now() |
| updated_at | TIMESTAMPTZ | NOT NULL, default now() |

#### persons
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| user_id | UUID | FK → users.id, NOT NULL |
| name | VARCHAR(100) | NOT NULL |
| relationship | VARCHAR(20) | NOT NULL, enum: parent/grandparent/other |
| phone | VARCHAR(20) | NULLABLE |
| created_at | TIMESTAMPTZ | NOT NULL, default now() |

#### invites
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| token | VARCHAR(32) | UNIQUE, NOT NULL |
| creator_id | UUID | FK → users.id, NOT NULL |
| person_id | UUID | FK → persons.id, NOT NULL |
| status | VARCHAR(20) | NOT NULL, default 'pending' |
| expires_at | TIMESTAMPTZ | NOT NULL |
| created_at | TIMESTAMPTZ | NOT NULL, default now() |

#### sessions
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| invite_id | UUID | FK → invites.id, NOT NULL |
| room_name | VARCHAR(100) | NOT NULL |
| status | VARCHAR(20) | NOT NULL, default 'waiting' |
| started_at | TIMESTAMPTZ | NULLABLE |
| ended_at | TIMESTAMPTZ | NULLABLE |
| created_at | TIMESTAMPTZ | NOT NULL, default now() |

#### recordings
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| session_id | UUID | FK → sessions.id, NOT NULL |
| storage_key | TEXT | NOT NULL |
| duration_seconds | INTEGER | NOT NULL |
| size_bytes | BIGINT | NOT NULL |
| created_at | TIMESTAMPTZ | NOT NULL, default now() |

## API Endpoints

### Authentication

| Method | Path | Request | Response | Auth |
|--------|------|---------|----------|------|
| POST | /api/auth/phone/start | `{ phone: string }` | `{ sent: boolean }` | None |
| POST | /api/auth/phone/verify | `{ phone: string, code: string }` | `{ token: string, user: User }` | None |
| POST | /api/auth/logout | - | `{ success: boolean }` | Required |

### Invites

| Method | Path | Request | Response | Auth |
|--------|------|---------|----------|------|
| POST | /api/invites | CreateInviteRequest | CreateInviteResponse | Required |
| GET | /api/invites | - | `{ invites: Invite[] }` | Required |
| GET | /api/invites/:token | - | `{ invite: Invite, person: Person }` | None |

### LiveKit

| Method | Path | Request | Response | Auth |
|--------|------|---------|----------|------|
| POST | /api/livekit/token | LiveKitTokenRequest | LiveKitTokenResponse | None* |

*Validates invite token instead of user auth

### Recordings

| Method | Path | Request | Response | Auth |
|--------|------|---------|----------|------|
| GET | /api/recordings | - | `{ recordings: Recording[] }` | Required |
| GET | /api/recordings/:id/url | - | `{ url: string, expiresAt: string }` | Required |

### Webhooks

| Method | Path | Request | Response | Auth |
|--------|------|---------|----------|------|
| POST | /api/webhooks/livekit | LiveKit webhook payload | `{ received: boolean }` | Signature |

## User Flows

### Flow 1: Child Creates Invite

1. Child opens web app at `/`
2. If not authenticated, redirects to `/auth/phone`
3. Child enters phone, receives OTP, verifies
4. Child fills form: parent name, relationship, optional phone
5. POST /api/invites creates person and invite
6. Child sees shareable link, can copy or send via SMS

### Flow 2: Parent Records Memory

1. Parent receives link, opens `/invite/:token`
2. GET /api/invites/:token validates invite is pending and not expired
3. If phone provided, prompts for OTP verification
4. Parent clicks "Start Recording"
5. POST /api/livekit/token returns JWT and room details
6. Frontend connects to LiveKit room
7. LiveKit dispatches agent, agent joins room
8. Agent greets parent, conducts interview
9. Parent hangs up
10. LiveKit egress triggers, webhook received
11. POST /api/webhooks/livekit updates session and creates recording

### Flow 3: Child Listens

1. Child opens app, sees list of invites with recordings
2. Child selects a recording
3. GET /api/recordings/:id/url returns signed R2 URL
4. Frontend plays audio via native audio element

## Environment Variables

All environment variables are defined in `.env.local` at repo root. The following are required:

```bash
# Required for all environments
DATABASE_URL=            # Neon Postgres connection string
LIVEKIT_API_KEY=         # LiveKit project API key
LIVEKIT_API_SECRET=      # LiveKit project API secret
LIVEKIT_URL=             # LiveKit WebSocket URL (wss://...)
R2_ACCESS_KEY_ID=        # Cloudflare R2 access key
R2_SECRET_ACCESS_KEY=    # Cloudflare R2 secret key
R2_BUCKET=               # R2 bucket name
R2_ENDPOINT=             # R2 endpoint URL
OPENAI_API_KEY=          # OpenAI API key (for agent)
TWILIO_ACCOUNT_SID=      # Twilio account SID
TWILIO_AUTH_TOKEN=       # Twilio auth token
TWILIO_PHONE_NUMBER=     # Twilio phone number for SMS

# Optional
APP_URL=http://localhost:3000  # Base URL for invite links
JWT_SECRET=              # Auto-generated if not provided
```

## Code Patterns

### Zod Schema Definition

All schemas are defined in `packages/contracts/src/schemas/`. Each schema file exports:

1. The Zod schema (e.g., `UserSchema`)
2. The inferred TypeScript type (e.g., `type User = z.infer<typeof UserSchema>`)

```typescript
// packages/contracts/src/schemas/user.ts
import * as z from "zod/v4";

export const UserSchema = z.object({
  id: z.string().uuid(),
  phone: z.string().regex(/^\+[1-9]\d{1,14}$/),
  createdAt: z.iso.datetime(),
  updatedAt: z.iso.datetime(),
});

export type User = z.infer<typeof UserSchema>;
```

### API Route Definition

All API routes use Hono with Zod validation:

```typescript
// apps/api/src/routes/example.ts
import { Hono } from "hono";
import { zValidator } from "@hono/zod-validator";
import { SomeRequestSchema, SomeResponseSchema } from "@ember/contracts";

export const exampleRouter = new Hono();

exampleRouter.post(
  "/",
  zValidator("json", SomeRequestSchema),
  async (c) => {
    const body = c.req.valid("json");
    // Business logic here
    const result = await doSomething(body);
    
    // Validate response matches contract
    const response = SomeResponseSchema.parse(result);
    return c.json(response);
  }
);
```

### React Component Pattern

Components use function declarations with explicit props types:

```typescript
// apps/web/src/components/Button.tsx
import type { ReactNode, ButtonHTMLAttributes } from "react";

type ButtonProps = ButtonHTMLAttributes<HTMLButtonElement> & {
  variant?: "primary" | "secondary";
  children: ReactNode;
};

export function Button({ variant = "primary", children, ...props }: ButtonProps) {
  const className = variant === "primary" 
    ? "bg-blue-500 text-white" 
    : "bg-gray-200 text-gray-800";
  
  return (
    <button className={className} {...props}>
      {children}
    </button>
  );
}
```

### Database Query Pattern

Database operations use Drizzle with explicit error handling:

```typescript
// apps/api/src/routes/invites.ts
import { createDb, invites } from "@ember/db";
import { eq } from "drizzle-orm";

async function getInviteByToken(dbUrl: string, token: string) {
  const db = createDb(dbUrl);
  
  const results = await db
    .select()
    .from(invites)
    .where(eq(invites.token, token))
    .limit(1);
  
  if (results.length === 0) {
    return null;
  }
  
  return results[0];
}
```

## Testing Strategy

### Unit Tests

Location: `**/*.test.ts` adjacent to source files
Runner: `bun test`
Pattern: Test pure functions, schema validations, utilities

```typescript
// packages/contracts/src/schemas/user.test.ts
import { describe, test, expect } from "bun:test";
import { UserSchema } from "./user";

describe("UserSchema", () => {
  test("validates correct user", () => {
    const result = UserSchema.safeParse({
      id: "550e8400-e29b-41d4-a716-446655440000",
      phone: "+14155551234",
      createdAt: "2025-01-01T00:00:00Z",
      updatedAt: "2025-01-01T00:00:00Z",
    });
    expect(result.success).toBe(true);
  });

  test("rejects invalid phone", () => {
    const result = UserSchema.safeParse({
      id: "550e8400-e29b-41d4-a716-446655440000",
      phone: "not-a-phone",
      createdAt: "2025-01-01T00:00:00Z",
      updatedAt: "2025-01-01T00:00:00Z",
    });
    expect(result.success).toBe(false);
  });
});
```

### Integration Tests

Location: `apps/*/tests/integration/`
Runner: `bun test`
Pattern: Test API endpoints with real database (test container)

### E2E Tests

Location: `apps/web/tests/e2e/`
Runner: Playwright (future addition)
Pattern: Test complete user flows

## Deployment

### Frontend (apps/web)

Deploy to Vercel:

1. Connect GitHub repo to Vercel
2. Set root directory to `apps/web`
3. Build command: `cd ../.. && bun install && bun run --filter @ember/web build`
4. Output directory: `dist`
5. Set environment variables in Vercel dashboard

### API (apps/api)

Deploy to Cloudflare Workers:

```bash
cd apps/api
bunx wrangler deploy
```

Or deploy to Fly.io:

```bash
cd apps/api
flyctl deploy
```

### Agent (apps/agent)

Deploy to LiveKit Cloud:

```bash
cd apps/agent
lk agent deploy
```

## Commands Reference

```bash
# Install all dependencies
just install

# Run all services in development
just dev

# Run individual services
just dev-web    # Frontend on :3000
just dev-api    # API on :8787
just dev-agent  # Agent locally

# Build all
just build

# Run tests
just test

# Type check
just typecheck

# Database operations
just db-generate  # Generate migration
just db-push      # Apply migrations

# Deploy
just deploy-agent  # Deploy agent to LiveKit Cloud

# Code quality
just fmt   # Format all code
just lint  # Lint all code
```

## Change Log

| Date | Version | Changes |
|------|---------|---------|
| 2025-11-25 | 1.0.0 | Initial specification |

---

*This document is the source of truth for Ember's technical architecture. All implementation must conform to these specifications. Changes require updating this document first.*
```

---

## Next Actions

1. **Now:** Copy the directory structure and create all files as specified above.

2. **Run setup:**
   ```bash
   bun install
   just build-contracts
   ```

3. **Create accounts and get credentials:**
   - Neon: Create project, get DATABASE_URL
   - LiveKit Cloud: Create project, get API key/secret/URL
   - Cloudflare R2: Create bucket, get credentials
   - Twilio: Get account SID, auth token, phone number
   - OpenAI: Get API key

4. **Configure environment:**
   ```bash
   cp .env.example .env.local
   # Fill in all values
   ```

5. **Initialize database:**
   ```bash
   just db-generate
   just db-push
   ```

6. **Start development:**
   ```bash
   just dev
   ```

**Success Metric:** By end of today, `just dev` should start both the web app and API server, and you should see "API server running on http://localhost:8787" in your terminal.



## Prompt:
11/25/2025, 12:12:51 PM

Okay, I am okay with this general structure although for the naming and conventions and folder structure I would prefer something simpler and more flexible.
I like the name contracts, but it might be unclear how contracts work and overlap with API-level data schema-level and no business domain-level. I want that clear separation, and I'm wondering if it's better to keep these closer to where the code is so I can develop on it together or I have the definitions separately because they will be consumed by other services and maybe external providers.
Is it better to start with the code and auto-generate the schemas, or have the schemas and then auto-generate the code templates?
And why? I like I have used Just before. Just files are this orthogonal to Nix because Just if it's just the build system, I think Nix could work here and it's quite pure. But generally, I think Nix and/or Just files can be a longer-term consideration for the next 90 days. I'm fine with Just as long as it can build because I'm not sure if this actually builds or if there's overlap with Nx Monorate. Though I think Just will be a good script runner, but then again I don't know why Bun workspaces wouldn't work.
What is a clean next step here? Recommendations. For today, I will have packages and UI component libraries, shared data contracts, and stuff, but mainly it's the front-end app and the back-end up and the LiveKit agent code in the Dockerfile in there that are of main concern and being able to manage all that in a model repo. And you know secrets and for LiveKit agents and AI agents, I need to containerize it and I will need GitHub actions for CICD. And I would need Playwright test for an end-to-end test.



## Response:
11/25/2025, 12:34:44 PM

````plaintext
Thought process: Reconciled contract organization, schema-first approach, and monorepo tooling decisions.

The user is asking several important clarifying questions about the architecture. Let me break down their concerns:

1. **Contracts clarity**: They want clear separation between API-level, data schema-level, and business domain-level. They're wondering if contracts should be co-located with code or separate.

2. **Schema-first vs Code-first**: Should they write schemas first and generate code, or write code and generate schemas?

3. **Just vs Nix vs Bun workspaces**: They want to understand the overlap and whether Just is necessary when Bun workspaces exist.

4. **Clean next step**: They want to focus on:
   - Frontend app
   - Backend app
   - LiveKit agent (containerized, needs Dockerfile)
   - Monorepo management
   - Secrets management
   - GitHub Actions for CI/CD
   - Playwright for E2E tests

Let me think through each of these carefully:

**1. Contracts organization**

The user raises a valid point. "Contracts" is ambiguous. There are several types of contracts:
- **Domain models**: Core business entities (User, Person, Invite, Session, Recording)
- **API contracts**: Request/response shapes for HTTP endpoints
- **Database schemas**: Table definitions
- **Wire protocols**: What gets serialized over the network

These can be organized in different ways:
- **Centralized**: All in one `packages/contracts` - good for sharing across services, but can become a "god package"
- **Co-located**: Keep schemas next to the code that uses them - better for iteration, but harder to share

For a small team/solo developer, I'd recommend a hybrid:
- Domain models are shared (they represent the business)
- API contracts are defined at the API layer (they're implementation details of the API)
- Database schema is in the db package (it's implementation)

But actually, for an MVP, the simplest approach is to keep everything together initially and split later if needed. The risk of over-engineering the separation is higher than the risk of coupling for a solo developer.
 
I see two primary approaches to defining schemas, each with distinct philosophical underpinnings. The schema-first method emphasizes designing the contract upfront, prioritizing clear interface definition before implementation. This approach works well for external API consumers, compelling developers to carefully consider interface design before diving into code. 

Conversely, the code-first method allows schemas to emerge organically from implementation, supporting rapid iteration and ensuring that generated schemas precisely reflect actual code behavior. This approach leverages TypeScript's strong typing to automatically generate schemas, OpenAPI specifications, and other contract representations.

The choice ultimately depends on project complexity, team preferences, and development stage. For an MVP, a flexible approach that doesn't prematurely constrain development might be most pragmatic. Nix offers comprehensive package management and build system capabilities, surpassing Just's functionality with greater complexity. The key distinctions between these tools reveal nuanced monorepo management strategies.

Workspace coordination involves multiple approaches: Bun handles package linking, Just manages task orchestration, and Bun scripts can partially replace Just's functionality. For a polyglot environment mixing TypeScript and Python, Just provides language-agnostic command execution and sophisticated workflow management.

Practical implementation suggests leveraging Bun scripts for TypeScript-only projects, while introducing Just becomes valuable in multi-language repositories requiring intricate task dependencies and cross-language command execution.

The primary focus remains streamlining development across frontend and backend applications, selecting tools that minimize friction and maximize developer productivity. I'll continue the structure exploration, focusing on creating a lean, efficient project layout that prioritizes simplicity and developer productivity.

The proposed structure emphasizes minimal nesting and clear service boundaries. By keeping top-level directories like web, api, and agent, we create an immediately understandable project topology. The shared folder enables type and schema sharing across services, which accelerates development and maintains type consistency.

Key design principles emerge: reduce complexity, enable rapid iteration, and maintain clean service separation. The workspace root configuration with Bun allows seamless dependency management and cross-package type sharing, supporting a modern, modular development approach.

The CI/CD and GitHub Actions workflows further streamline the development process, automating testing, linting, and deployment with minimal configuration overhead.
````

# Clarifying the Architecture: Simpler, Cleaner, Practical

## TL;DR

Your instincts are correct on all counts. Let me address each concern directly, then give you a clean next step that you can execute today.

**Contracts clarity:** Separate domain models (the business) from API contracts (the HTTP interface) from database schema (the storage). Domain models live in a shared package. API contracts live with the API code. Database schema lives with the database code.

**Schema-first vs Code-first:** For shared types consumed by multiple services, write schemas first. For implementation details, write code first and let types emerge. Practically: Zod schemas for domain models, TypeScript interfaces for internal API structures.

**Just vs Bun workspaces:** Bun workspaces handle package linking. Just is an optional task runner for convenience. You don't need Just for MVP. Bun's `package.json` scripts work fine. Add Just later if you want polyglot orchestration (TypeScript + Python + Rust).

**Clean next step:** I'll give you a minimal structure with three folders (web, api, agent), one shared folder for domain schemas, and working GitHub Actions CI. No unnecessary abstraction.

---

## Part 1: Understanding the Layers of "Contracts"

Your question about where contracts belong reveals a real architectural decision. Let me explain the three layers clearly, because this determines where code lives.

**Layer 1: Domain Models**

These are the core business entities that exist independent of how you store or transmit them. A User is a User whether it's in Postgres, in a JSON API response, or in a Python dataclass. Domain models answer "what things exist in my business?" They are stable and change slowly.

For Ember, your domain models are User, Person, Invite, Session, and Recording. These should live in a shared location because the web app needs to know what a User is, the API needs to validate User data, and the Python agent needs to understand User metadata.

**Layer 2: API Contracts**

These are the shapes of HTTP requests and responses. A CreateInviteRequest is not a domain model; it's a data transfer object specific to your REST API. If you later add a GraphQL API or a gRPC service, you'd have different request shapes but the same domain models.

API contracts answer "how does data flow over the network?" They belong with the API code because they're implementation details of the API. The web app doesn't need to know about CreateInviteRequest; it just calls a function that internally uses that shape.

**Layer 3: Database Schema**

This is how you persist domain models. A users table is not the same as a User domain model. The table might have internal columns (password hashes, soft delete flags, audit timestamps) that aren't part of the domain model. The schema might denormalize for performance.

Database schema answers "how do I store things?" It belongs with the database code because it's an implementation detail of persistence. The API transforms between database rows and domain models.

**The Practical Implication**

For your MVP, here's what this means:

```
ember/
├── shared/
│   └── domain/           # Domain models (shared across all services)
│       ├── package.json
│       └── src/
│           ├── user.ts       # UserSchema, type User
│           ├── person.ts     # PersonSchema, type Person
│           ├── invite.ts     # InviteSchema, type Invite
│           ├── session.ts    # SessionSchema, type Session
│           ├── recording.ts  # RecordingSchema, type Recording
│           └── index.ts      # Barrel export
│
├── api/
│   └── src/
│       ├── contracts/    # API-specific request/response shapes
│       │   ├── auth.ts       # AuthStartRequest, AuthVerifyRequest
│       │   ├── invites.ts    # CreateInviteRequest, CreateInviteResponse
│       │   └── livekit.ts    # TokenRequest, TokenResponse
│       ├── db/           # Database schema, co-located with API
│       │   ├── schema.ts
│       │   └── client.ts
│       └── routes/
│
├── web/                  # Frontend imports from @ember/domain
│
└── agent/                # Python agent (generates types from JSON Schema)
```

This structure has clear ownership: domain models are shared truth, API contracts are API implementation, database schema is storage implementation.

---

## Part 2: Schema-First vs Code-First

This question has a nuanced answer that depends on what you're building.

**When to write schemas first:**

Write schemas first when the schema is a contract between systems. Your domain models are consumed by the web app, the API, and the Python agent. If you change the User schema, all three need to update. The schema IS the source of truth, and the code implements it.

Zod is excellent for this because you write the schema once and get:
1. Runtime validation
2. TypeScript type inference
3. JSON Schema export (for Python type generation)

You write `UserSchema`, and TypeScript infers `type User`. You export to JSON Schema, and Python generates a dataclass.

**When to write code first:**

Write code first when you're exploring and the schema isn't stable. API request/response shapes often evolve as you build features. Writing a formal schema for CreateInviteRequest before you've implemented invite creation adds friction without benefit.

For implementation details, let the code lead. Define your TypeScript interface inline, then extract it to a schema later if you need validation.

**Practical recommendation for Ember:**

Start with domain schemas (schema-first) because they're stable and shared. Keep API contracts as TypeScript types initially (code-first) and add Zod validation as you solidify the API. This gives you speed where you need it (API iteration) and stability where you need it (domain models).

```typescript
// shared/domain/src/user.ts — Schema-first, stable, shared
import * as z from "zod/v4";

export const UserSchema = z.object({
  id: z.string().uuid(),
  phone: z.string().regex(/^\+[1-9]\d{1,14}$/),
  createdAt: z.iso.datetime(),
  updatedAt: z.iso.datetime(),
});

export type User = z.infer<typeof UserSchema>;


// api/src/routes/auth.ts — Code-first, evolving, local
interface AuthStartRequest {
  phone: string;
}

interface AuthVerifyRequest {
  phone: string;
  code: string;
}

// Later, if you need validation:
const AuthStartRequestSchema = z.object({
  phone: z.string().regex(/^\+[1-9]\d{1,14}$/),
});
```

---

## Part 3: Just vs Bun Workspaces vs Nix

Let me clarify what each tool does, because they solve different problems.

**Bun workspaces** are a package manager feature. When you have multiple packages in a monorepo, workspaces let them depend on each other. If `api` depends on `@ember/domain`, Bun creates a symlink so imports resolve correctly. This is not optional for a TypeScript monorepo; you need it or something equivalent (npm workspaces, pnpm workspaces).

Bun workspaces give you:
- `bun install` installs all packages from root
- `@ember/domain` imports resolve to `shared/domain/src`
- Shared dependencies are hoisted to root `node_modules`

**Just** is a command runner. It's like `make` but with a simpler syntax. Just doesn't understand packages or dependencies; it just runs shell commands. You write recipes that call `bun`, `python`, `docker`, whatever.

Just gives you:
- A single place to define common tasks
- Dependencies between tasks (build contracts before building api)
- Cross-platform commands (no bash-isms)
- Polyglot support (same tool for TypeScript and Python)

**Do you need Just?** For TypeScript-only, no. Use `package.json` scripts:

```json
{
  "scripts": {
    "dev": "bun --filter '*' run dev",
    "build": "bun --filter '@ember/domain' run build && bun --filter '@ember/api' run build",
    "test": "bun test"
  }
}
```

For TypeScript + Python, Just helps:

```makefile
# justfile
dev:
    bun --filter '*' run dev &
    cd agent && uv run python -m src.agent &
    wait

build:
    bun --filter '@ember/domain' run build
    bun --filter '@ember/web' run build
    bun --filter '@ember/api' run build
    cd agent && docker build -t ember-agent .
```

**Nix** is a whole different level. Nix is a purely functional package manager that guarantees reproducible builds. It can replace Bun, Just, Docker, and system package managers. If you go full Nix, you define your entire development environment declaratively.

Nix gives you:
- Reproducible builds across machines
- No "works on my machine" problems
- Hermetic build environment
- Can generate Docker images, deployments, etc.

**Do you need Nix?** Not for MVP. Nix has a steep learning curve. Add it later if you want reproducibility guarantees. For now, Bun + optional Just is sufficient.

**My recommendation:** Start with Bun workspaces only. Add Just if you find yourself writing complex `package.json` scripts or need to orchestrate Python commands. Add Nix later for reproducibility.

---

## Part 4: Simplified Structure for MVP

Based on your priorities (frontend, backend, agent, CI/CD, E2E tests), here's the minimal structure:

```
ember/
├── .github/
│   └── workflows/
│       └── ci.yml                # Lint, typecheck, test, build
│
├── .env.example                  # Template
├── .env.local                    # Your secrets (gitignored)
├── package.json                  # Workspace root
├── tsconfig.json                 # Base TypeScript config
├── biome.json                    # Linting/formatting
├── playwright.config.ts          # E2E test config
│
├── web/                          # React + Vite frontend
│   ├── package.json
│   ├── tsconfig.json
│   ├── vite.config.ts
│   ├── index.html
│   ├── src/
│   │   ├── main.tsx
│   │   ├── App.tsx
│   │   ├── routes/               # TanStack Router pages
│   │   ├── components/
│   │   ├── hooks/
│   │   └── lib/
│   │       └── api.ts            # API client
│   └── e2e/                      # Playwright tests
│       └── invite-flow.spec.ts
│
├── api/                          # HonoJS backend
│   ├── package.json
│   ├── tsconfig.json
│   ├── src/
│   │   ├── index.ts              # Entry point
│   │   ├── routes/
│   │   │   ├── auth.ts
│   │   │   ├── invites.ts
│   │   │   ├── livekit.ts
│   │   │   └── webhooks.ts
│   │   ├── db/                   # Database schema + client
│   │   │   ├── schema.ts
│   │   │   ├── client.ts
│   │   │   └── migrations/
│   │   └── lib/
│   │       ├── auth.ts           # BetterAuth config
│   │       └── storage.ts        # R2 client
│   └── tests/
│       └── invites.test.ts
│
├── agent/                        # Python LiveKit agent
│   ├── pyproject.toml
│   ├── Dockerfile
│   ├── livekit.toml
│   └── src/
│       ├── __init__.py
│       ├── agent.py
│       └── prompts.py
│
└── shared/                       # Shared code
    └── domain/                   # Domain schemas
        ├── package.json
        └── src/
            ├── schemas.ts        # All Zod schemas
            └── index.ts
```

This is flat, minimal, and each folder has a clear purpose. No `apps/` wrapper, no `packages/` wrapper. The structure scales when needed but doesn't force nesting now.

---

## Part 5: Step-by-Step Setup (Execute Today)

### Step 1: Create the monorepo root

```bash
mkdir ember && cd ember
```

Create `package.json`:

```json
{
  "name": "ember",
  "private": true,
  "workspaces": ["web", "api", "shared/*"],
  "scripts": {
    "dev": "bun run dev:api & bun run dev:web & wait",
    "dev:web": "bun --filter @ember/web run dev",
    "dev:api": "bun --filter @ember/api run dev",
    "build": "bun run build:domain && bun run build:web && bun run build:api",
    "build:domain": "bun --filter @ember/domain run build",
    "build:web": "bun --filter @ember/web run build",
    "build:api": "bun --filter @ember/api run build",
    "test": "bun test",
    "test:e2e": "playwright test",
    "typecheck": "tsc -b",
    "lint": "biome check .",
    "fmt": "biome format --write ."
  },
  "devDependencies": {
    "@biomejs/biome": "^1.9.4",
    "@playwright/test": "^1.49.1",
    "typescript": "^5.7.2"
  }
}
```

Create `tsconfig.json`:

```json
{
  "compilerOptions": {
    "target": "ES2024",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "strict": true,
    "noEmit": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "verbatimModuleSyntax": true,
    "lib": ["ES2024", "DOM", "DOM.Iterable"]
  },
  "references": [
    { "path": "./shared/domain" },
    { "path": "./web" },
    { "path": "./api" }
  ]
}
```

Create `biome.json`:

```json
{
  "$schema": "https://biomejs.dev/schemas/1.9.4/schema.json",
  "organizeImports": { "enabled": true },
  "linter": { "enabled": true, "rules": { "recommended": true } },
  "formatter": { "enabled": true, "indentStyle": "space", "indentWidth": 2 }
}
```

Create `.env.example`:

```bash
# Database
DATABASE_URL=postgresql://user:pass@host/db?sslmode=require

# LiveKit
LIVEKIT_API_KEY=
LIVEKIT_API_SECRET=
LIVEKIT_URL=wss://your-project.livekit.cloud

# Storage (R2)
R2_ENDPOINT=
R2_ACCESS_KEY_ID=
R2_SECRET_ACCESS_KEY=
R2_BUCKET=ember-recordings

# OpenAI (for agent)
OPENAI_API_KEY=

# Twilio (for SMS)
TWILIO_ACCOUNT_SID=
TWILIO_AUTH_TOKEN=
TWILIO_PHONE_NUMBER=

# App
APP_URL=http://localhost:3000
```

Create `.gitignore`:

```
node_modules/
dist/
.env.local
*.local
.DS_Store
__pycache__/
*.pyc
.venv/
```

### Step 2: Create the shared domain package

```bash
mkdir -p shared/domain/src
```

Create `shared/domain/package.json`:

```json
{
  "name": "@ember/domain",
  "version": "0.0.1",
  "private": true,
  "type": "module",
  "exports": {
    ".": "./src/index.ts"
  },
  "scripts": {
    "build": "tsc",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "zod": "^3.25.0"
  },
  "devDependencies": {
    "typescript": "^5.7.2"
  }
}
```

Create `shared/domain/tsconfig.json`:

```json
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "composite": true,
    "outDir": "dist",
    "rootDir": "src"
  },
  "include": ["src/**/*"]
}
```

Create `shared/domain/src/schemas.ts`:

```typescript
import * as z from "zod/v4";

// ============================================================
// Core Domain Models
// ============================================================

export const UserSchema = z.object({
  id: z.string().uuid(),
  phone: z.string().regex(/^\+[1-9]\d{1,14}$/, "Invalid phone format"),
  createdAt: z.coerce.date(),
  updatedAt: z.coerce.date(),
});

export const PersonSchema = z.object({
  id: z.string().uuid(),
  userId: z.string().uuid(),
  name: z.string().min(1).max(100),
  relationship: z.enum(["parent", "grandparent", "other"]),
  phone: z.string().regex(/^\+[1-9]\d{1,14}$/).optional(),
  createdAt: z.coerce.date(),
});

export const InviteStatusSchema = z.enum(["pending", "accepted", "expired", "revoked"]);

export const InviteSchema = z.object({
  id: z.string().uuid(),
  token: z.string().length(32),
  creatorId: z.string().uuid(),
  personId: z.string().uuid(),
  status: InviteStatusSchema,
  expiresAt: z.coerce.date(),
  createdAt: z.coerce.date(),
});

export const SessionStatusSchema = z.enum(["waiting", "active", "completed", "failed"]);

export const SessionSchema = z.object({
  id: z.string().uuid(),
  inviteId: z.string().uuid(),
  roomName: z.string(),
  status: SessionStatusSchema,
  startedAt: z.coerce.date().optional(),
  endedAt: z.coerce.date().optional(),
  createdAt: z.coerce.date(),
});

export const RecordingSchema = z.object({
  id: z.string().uuid(),
  sessionId: z.string().uuid(),
  storageKey: z.string(),
  durationSeconds: z.number().int().positive(),
  sizeBytes: z.number().int().positive(),
  createdAt: z.coerce.date(),
});

// ============================================================
// Type Exports
// ============================================================

export type User = z.infer<typeof UserSchema>;
export type Person = z.infer<typeof PersonSchema>;
export type InviteStatus = z.infer<typeof InviteStatusSchema>;
export type Invite = z.infer<typeof InviteSchema>;
export type SessionStatus = z.infer<typeof SessionStatusSchema>;
export type Session = z.infer<typeof SessionSchema>;
export type Recording = z.infer<typeof RecordingSchema>;
```

Create `shared/domain/src/index.ts`:

```typescript
export * from "./schemas.js";
```

### Step 3: Create the API

```bash
mkdir -p api/src/{routes,db,lib}
mkdir -p api/tests
```

Create `api/package.json`:

```json
{
  "name": "@ember/api",
  "version": "0.0.1",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "bun --hot src/index.ts",
    "build": "bun build src/index.ts --outdir dist --target bun",
    "typecheck": "tsc --noEmit",
    "db:generate": "drizzle-kit generate",
    "db:push": "drizzle-kit push"
  },
  "dependencies": {
    "@ember/domain": "workspace:*",
    "@hono/zod-validator": "^0.4.1",
    "@livekit/protocol": "^1.31.0",
    "@neondatabase/serverless": "^0.10.4",
    "drizzle-orm": "^0.38.3",
    "hono": "^4.6.14",
    "livekit-server-sdk": "^2.9.1"
  },
  "devDependencies": {
    "drizzle-kit": "^0.30.1",
    "typescript": "^5.7.2"
  }
}
```

Create `api/tsconfig.json`:

```json
{
  "extends": "../tsconfig.json",
  "compilerOptions": {
    "composite": true,
    "outDir": "dist",
    "rootDir": "src",
    "types": ["bun-types"]
  },
  "include": ["src/**/*"],
  "references": [{ "path": "../shared/domain" }]
}
```

Create `api/src/index.ts`:

```typescript
import { Hono } from "hono";
import { cors } from "hono/cors";
import { logger } from "hono/logger";
import { invitesRouter } from "./routes/invites.js";
import { livekitRouter } from "./routes/livekit.js";
import { webhooksRouter } from "./routes/webhooks.js";

const app = new Hono();

// Middleware
app.use("*", logger());
app.use("*", cors({ origin: "http://localhost:3000", credentials: true }));

// Health check
app.get("/health", (c) => c.json({ status: "ok", timestamp: new Date().toISOString() }));

// Routes
app.route("/api/invites", invitesRouter);
app.route("/api/livekit", livekitRouter);
app.route("/api/webhooks", webhooksRouter);

// Start server
const port = Number(process.env.PORT) || 8787;
console.log(`🚀 API running at http://localhost:${port}`);

export default { port, fetch: app.fetch };
```

Create `api/src/db/schema.ts`:

```typescript
import { pgTable, uuid, varchar, timestamp, text, integer, bigint } from "drizzle-orm/pg-core";

export const users = pgTable("users", {
  id: uuid("id").primaryKey().defaultRandom(),
  phone: varchar("phone", { length: 20 }).notNull().unique(),
  createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
  updatedAt: timestamp("updated_at", { withTimezone: true }).notNull().defaultNow(),
});

export const persons = pgTable("persons", {
  id: uuid("id").primaryKey().defaultRandom(),
  userId: uuid("user_id").notNull().references(() => users.id),
  name: varchar("name", { length: 100 }).notNull(),
  relationship: varchar("relationship", { length: 20 }).notNull(),
  phone: varchar("phone", { length: 20 }),
  createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
});

export const invites = pgTable("invites", {
  id: uuid("id").primaryKey().defaultRandom(),
  token: varchar("token", { length: 32 }).notNull().unique(),
  creatorId: uuid("creator_id").notNull().references(() => users.id),
  personId: uuid("person_id").notNull().references(() => persons.id),
  status: varchar("status", { length: 20 }).notNull().default("pending"),
  expiresAt: timestamp("expires_at", { withTimezone: true }).notNull(),
  createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
});

export const sessions = pgTable("sessions", {
  id: uuid("id").primaryKey().defaultRandom(),
  inviteId: uuid("invite_id").notNull().references(() => invites.id),
  roomName: varchar("room_name", { length: 100 }).notNull(),
  status: varchar("status", { length: 20 }).notNull().default("waiting"),
  startedAt: timestamp("started_at", { withTimezone: true }),
  endedAt: timestamp("ended_at", { withTimezone: true }),
  createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
});

export const recordings = pgTable("recordings", {
  id: uuid("id").primaryKey().defaultRandom(),
  sessionId: uuid("session_id").notNull().references(() => sessions.id),
  storageKey: text("storage_key").notNull(),
  durationSeconds: integer("duration_seconds").notNull(),
  sizeBytes: bigint("size_bytes", { mode: "number" }).notNull(),
  createdAt: timestamp("created_at", { withTimezone: true }).notNull().defaultNow(),
});
```

Create `api/src/db/client.ts`:

```typescript
import { neon } from "@neondatabase/serverless";
import { drizzle } from "drizzle-orm/neon-http";
import * as schema from "./schema.js";

export function createDb(url: string) {
  const sql = neon(url);
  return drizzle(sql, { schema });
}

export type Database = ReturnType<typeof createDb>;
export * from "./schema.js";
```

Create `api/drizzle.config.ts`:

```typescript
import { defineConfig } from "drizzle-kit";

export default defineConfig({
  schema: "./src/db/schema.ts",
  out: "./src/db/migrations",
  dialect: "postgresql",
  dbCredentials: { url: process.env.DATABASE_URL! },
});
```

Create `api/src/routes/invites.ts`:

```typescript
import { Hono } from "hono";
import { zValidator } from "@hono/zod-validator";
import * as z from "zod/v4";
import { createDb, invites, persons } from "../db/client.js";
import { randomBytes } from "node:crypto";

// API-specific request schema (lives with the route)
const CreateInviteRequest = z.object({
  personName: z.string().min(1).max(100),
  personPhone: z.string().regex(/^\+[1-9]\d{1,14}$/).optional(),
  relationship: z.enum(["parent", "grandparent", "other"]),
});

export const invitesRouter = new Hono();

invitesRouter.post("/", zValidator("json", CreateInviteRequest), async (c) => {
  const body = c.req.valid("json");
  const db = createDb(process.env.DATABASE_URL!);

  // Generate unique token
  const token = randomBytes(16).toString("hex");

  // In production: get userId from auth context
  const userId = "00000000-0000-0000-0000-000000000000"; // Placeholder

  // Create person
  const [person] = await db
    .insert(persons)
    .values({
      userId,
      name: body.personName,
      relationship: body.relationship,
      phone: body.personPhone,
    })
    .returning();

  // Create invite (expires in 7 days)
  const expiresAt = new Date();
  expiresAt.setDate(expiresAt.getDate() + 7);

  const [invite] = await db
    .insert(invites)
    .values({
      token,
      creatorId: userId,
      personId: person.id,
      expiresAt,
    })
    .returning();

  const baseUrl = process.env.APP_URL || "http://localhost:3000";

  return c.json({
    inviteId: invite.id,
    inviteUrl: `${baseUrl}/invite/${token}`,
    expiresAt: invite.expiresAt.toISOString(),
  });
});
```

Create `api/src/routes/livekit.ts`:

```typescript
import { Hono } from "hono";
import { zValidator } from "@hono/zod-validator";
import * as z from "zod/v4";
import { AccessToken, VideoGrant } from "livekit-server-sdk";
import { RoomConfiguration, RoomAgentDispatch } from "@livekit/protocol";
import { createDb, invites, sessions } from "../db/client.js";
import { eq } from "drizzle-orm";

const TokenRequest = z.object({
  inviteToken: z.string().length(32),
});

export const livekitRouter = new Hono();

livekitRouter.post("/token", zValidator("json", TokenRequest), async (c) => {
  const { inviteToken } = c.req.valid("json");
  const db = createDb(process.env.DATABASE_URL!);

  // Find and validate invite
  const [invite] = await db
    .select()
    .from(invites)
    .where(eq(invites.token, inviteToken))
    .limit(1);

  if (!invite) {
    return c.json({ error: "Invite not found" }, 404);
  }

  if (invite.status !== "pending") {
    return c.json({ error: "Invite already used" }, 400);
  }

  if (new Date() > invite.expiresAt) {
    return c.json({ error: "Invite expired" }, 400);
  }

  // Create room and session
  const roomName = `ember-${invite.id}`;

  await db.insert(sessions).values({
    inviteId: invite.id,
    roomName,
    status: "waiting",
  });

  // Generate token with agent dispatch
  const at = new AccessToken(
    process.env.LIVEKIT_API_KEY!,
    process.env.LIVEKIT_API_SECRET!,
    { identity: `participant-${invite.personId}`, name: "Participant" }
  );

  const grant: VideoGrant = {
    room: roomName,
    roomJoin: true,
    canPublish: true,
    canSubscribe: true,
  };

  at.addGrant(grant);
  at.roomConfig = new RoomConfiguration({
    agents: [
      new RoomAgentDispatch({
        agentName: "ember-agent",
        metadata: JSON.stringify({ inviteId: invite.id, personId: invite.personId }),
      }),
    ],
  });

  return c.json({
    token: await at.toJwt(),
    roomName,
    serverUrl: process.env.LIVEKIT_URL,
  });
});
```

Create `api/src/routes/webhooks.ts`:

```typescript
import { Hono } from "hono";
import { createDb, sessions, recordings } from "../db/client.js";
import { eq } from "drizzle-orm";

export const webhooksRouter = new Hono();

webhooksRouter.post("/livekit", async (c) => {
  // In production: verify webhook signature
  const payload = await c.req.json();

  if (payload.event === "egress_ended") {
    const db = createDb(process.env.DATABASE_URL!);
    const roomName = payload.egressInfo?.roomName;
    const fileInfo = payload.egressInfo?.file;

    if (roomName && fileInfo) {
      // Find session by room name
      const [session] = await db
        .select()
        .from(sessions)
        .where(eq(sessions.roomName, roomName))
        .limit(1);

      if (session) {
        // Create recording
        await db.insert(recordings).values({
          sessionId: session.id,
          storageKey: fileInfo.filename,
          durationSeconds: Math.floor(fileInfo.duration / 1000000000), // nanoseconds to seconds
          sizeBytes: fileInfo.size,
        });

        // Update session status
        await db
          .update(sessions)
          .set({ status: "completed", endedAt: new Date() })
          .where(eq(sessions.id, session.id));
      }
    }
  }

  return c.json({ received: true });
});
```

### Step 4: Create the frontend

```bash
mkdir -p web/src/{routes,components,hooks,lib}
mkdir -p web/e2e
```

Create `web/package.json`:

```json
{
  "name": "@ember/web",
  "version": "0.0.1",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc -b && vite build",
    "preview": "vite preview",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "@ember/domain": "workspace:*",
    "@livekit/components-react": "^2.7.3",
    "@tanstack/react-query": "^5.62.8",
    "@tanstack/react-router": "^1.93.1",
    "livekit-client": "^2.8.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  },
  "devDependencies": {
    "@tanstack/router-devtools": "^1.93.1",
    "@tanstack/router-plugin": "^1.93.1",
    "@types/react": "^19.0.2",
    "@types/react-dom": "^19.0.2",
    "@vitejs/plugin-react": "^4.3.4",
    "typescript": "^5.7.2",
    "vite": "^6.0.3"
  }
}
```

Create `web/tsconfig.json`:

```json
{
  "extends": "../tsconfig.json",
  "compilerOptions": {
    "composite": true,
    "outDir": "dist",
    "rootDir": "src",
    "jsx": "react-jsx"
  },
  "include": ["src/**/*"],
  "references": [{ "path": "../shared/domain" }]
}
```

Create `web/vite.config.ts`:

```typescript
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import { TanStackRouterVite } from "@tanstack/router-plugin/vite";

export default defineConfig({
  plugins: [TanStackRouterVite(), react()],
  server: {
    port: 3000,
    proxy: {
      "/api": { target: "http://localhost:8787", changeOrigin: true },
    },
  },
});
```

Create `web/index.html`:

```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Ember</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
```

Create `web/src/main.tsx`:

```typescript
import { StrictMode } from "react";
import { createRoot } from "react-dom/client";
import { RouterProvider, createRouter } from "@tanstack/react-router";
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";
import { routeTree } from "./routeTree.gen";

const queryClient = new QueryClient();
const router = createRouter({ routeTree });

declare module "@tanstack/react-router" {
  interface Register {
    router: typeof router;
  }
}

createRoot(document.getElementById("root")!).render(
  <StrictMode>
    <QueryClientProvider client={queryClient}>
      <RouterProvider router={router} />
    </QueryClientProvider>
  </StrictMode>
);
```

Create `web/src/routes/__root.tsx`:

```typescript
import { createRootRoute, Outlet } from "@tanstack/react-router";

export const Route = createRootRoute({
  component: () => (
    <div style={{ fontFamily: "system-ui, sans-serif", padding: "2rem" }}>
      <Outlet />
    </div>
  ),
});
```

Create `web/src/routes/index.tsx`:

```typescript
import { createFileRoute } from "@tanstack/react-router";

export const Route = createFileRoute("/")({
  component: HomePage,
});

function HomePage() {
  return (
    <div>
      <h1>Ember</h1>
      <p>Family voices, preserved forever.</p>
    </div>
  );
}
```

### Step 5: Create the agent

```bash
mkdir -p agent/src
```

Create `agent/pyproject.toml`:

```toml
[project]
name = "ember-agent"
version = "0.1.0"
requires-python = ">=3.12"
dependencies = [
    "livekit-agents>=0.12.0",
    "livekit-plugins-openai>=0.10.0",
    "livekit-plugins-silero>=0.7.0",
    "python-dotenv>=1.0.0",
]

[tool.uv]
dev-dependencies = ["ruff>=0.8.0"]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

Create `agent/livekit.toml`:

```toml
[agent]
name = "ember-agent"

[build]
dockerfile = "Dockerfile"
```

Create `agent/Dockerfile`:

```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Install uv
RUN pip install uv

# Copy files
COPY pyproject.toml .
COPY src/ src/

# Install dependencies
RUN uv sync --frozen

# Run agent
CMD ["uv", "run", "python", "-m", "src.agent"]
```

Create `agent/src/__init__.py`:

```python
"""Ember voice AI agent."""
```

Create `agent/src/agent.py`:

```python
"""Ember voice agent that interviews family members."""

import json
import logging
from livekit import agents
from livekit.agents import JobContext, WorkerOptions, cli
from livekit.agents.voice import VoiceAgent
from livekit.plugins import openai, silero

logger = logging.getLogger("ember-agent")

SYSTEM_PROMPT = """You are a warm, patient interviewer helping someone record 
memories and stories for their family. Ask open-ended questions about life 
experiences, memories, and wisdom they want to share. Be encouraging and help 
them feel comfortable. Keep responses brief to let them do most of the talking."""


async def entrypoint(ctx: JobContext):
    """Main agent entrypoint."""
    logger.info(f"Agent started for room: {ctx.room.name}")

    # Parse dispatch metadata
    metadata = {}
    if ctx.job.agent_dispatch and ctx.job.agent_dispatch.metadata:
        metadata = json.loads(ctx.job.agent_dispatch.metadata)

    logger.info(f"Invite: {metadata.get('inviteId')}, Person: {metadata.get('personId')}")

    await ctx.connect()
    participant = await ctx.wait_for_participant()
    logger.info(f"Participant joined: {participant.identity}")

    # Create voice agent
    agent = VoiceAgent(
        vad=silero.VAD.load(),
        stt=openai.STT(),
        llm=openai.LLM(model="gpt-4o"),
        tts=openai.TTS(voice="alloy"),
        chat_ctx=agents.ChatContext(
            messages=[agents.ChatMessage(role="system", content=SYSTEM_PROMPT)]
        ),
    )

    agent.start(ctx.room, participant)
    await agent.say("Hello! I'm so glad you're here. What memory would you like to start with?")


if __name__ == "__main__":
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))
```

### Step 6: Create GitHub Actions CI

Create `.github/workflows/ci.yml`:

```yaml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  lint-and-typecheck:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      - name: Lint
        run: bun run lint

      - name: Typecheck
        run: bun run typecheck

  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      - name: Run tests
        run: bun run test

  build:
    runs-on: ubuntu-latest
    needs: [lint-and-typecheck, test]
    steps:
      - uses: actions/checkout@v4

      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      - name: Build
        run: bun run build

  e2e:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - uses: actions/checkout@v4

      - uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      - name: Install Playwright
        run: bunx playwright install --with-deps chromium

      - name: Run E2E tests
        run: bun run test:e2e
```

Create `playwright.config.ts` at root:

```typescript
import { defineConfig } from "@playwright/test";

export default defineConfig({
  testDir: "./web/e2e",
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: "html",
  use: {
    baseURL: "http://localhost:3000",
    trace: "on-first-retry",
  },
  webServer: {
    command: "bun run dev",
    url: "http://localhost:3000",
    reuseExistingServer: !process.env.CI,
  },
});
```

Create `web/e2e/home.spec.ts`:

```typescript
import { test, expect } from "@playwright/test";

test("homepage loads", async ({ page }) => {
  await page.goto("/");
  await expect(page.getByRole("heading", { name: "Ember" })).toBeVisible();
});
```

### Step 7: Install and verify

```bash
# Install all dependencies
bun install

# Install Python agent dependencies
cd agent && pip install uv && uv sync && cd ..

# Verify TypeScript compiles
bun run typecheck

# Verify lint passes
bun run lint

# Start development servers
bun run dev
```

---

## Part 6: Specification Document for Coding Agents

Save this as `SPEC.md` at your repo root. This is the single source of truth for coding agents.

````markdown
# Ember Technical Specification

Version: 1.0.0  
Created: 2025-11-25  
Freeze Until: 2025-02-25

## Overview

Ember is a voice memory platform where children invite parents/grandparents to record stories with an AI interviewer. This document is the authoritative specification for all implementation.

## Architecture

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│   web/      │────▶│   api/      │────▶│ Neon PG     │
│ Vite+React  │     │   HonoJS    │     │ (Database)  │
└─────────────┘     └──────┬──────┘     └─────────────┘
                           │
                           ▼
                    ┌─────────────┐     ┌─────────────┐
                    │ LiveKit     │◀────│   agent/    │
                    │ Cloud       │     │   Python    │
                    └─────────────┘     └─────────────┘
                           │
                           ▼
                    ┌─────────────┐
                    │ Cloudflare  │
                    │ R2 Storage  │
                    └─────────────┘
```

## Directory Structure

```
ember/
├── .env.local              # Environment (gitignored)
├── .env.example            # Template
├── package.json            # Workspace root
├── tsconfig.json           # Base TS config
├── biome.json              # Lint/format
├── playwright.config.ts    # E2E config
├── SPEC.md                 # This file
│
├── .github/workflows/
│   └── ci.yml              # CI pipeline
│
├── web/                    # Frontend
│   ├── package.json
│   ├── tsconfig.json
│   ├── vite.config.ts
│   ├── index.html
│   ├── src/
│   │   ├── main.tsx
│   │   ├── routes/         # TanStack Router file routes
│   │   ├── components/
│   │   ├── hooks/
│   │   └── lib/
│   └── e2e/                # Playwright tests
│
├── api/                    # Backend
│   ├── package.json
│   ├── tsconfig.json
│   ├── drizzle.config.ts
│   ├── src/
│   │   ├── index.ts        # Hono app entry
│   │   ├── routes/         # API routes
│   │   ├── db/             # Schema + client
│   │   └── lib/            # Utilities
│   └── tests/
│
├── agent/                  # Python AI agent
│   ├── pyproject.toml
│   ├── livekit.toml
│   ├── Dockerfile
│   └── src/
│       ├── __init__.py
│       └── agent.py
│
└── shared/
    └── domain/             # Shared schemas
        ├── package.json
        └── src/
            ├── schemas.ts
            └── index.ts
```

## Technology Versions (Locked)

| Tech | Version | Package |
|------|---------|---------|
| TypeScript | 5.7.x | `typescript@^5.7.2` |
| Bun | 1.3.x | Runtime |
| React | 19.x | `react@^19.0.0` |
| Vite | 6.x | `vite@^6.0.3` |
| HonoJS | 4.x | `hono@^4.6.14` |
| Drizzle | 0.38.x | `drizzle-orm@^0.38.3` |
| Zod | 4.x | `zod@^3.25.0` (use `zod/v4` import) |
| TanStack Router | 1.x | `@tanstack/react-router@^1.93.1` |
| TanStack Query | 5.x | `@tanstack/react-query@^5.62.8` |
| LiveKit Client | 2.x | `livekit-client@^2.8.0` |
| Python | 3.12.x | Runtime |
| LiveKit Agents | 0.12.x | `livekit-agents>=0.12.0` |

## Environment Variables

All variables defined in `.env.local` at repo root:

```bash
# Database (required)
DATABASE_URL=postgresql://...

# LiveKit (required)
LIVEKIT_API_KEY=
LIVEKIT_API_SECRET=
LIVEKIT_URL=wss://...

# Storage (required)
R2_ENDPOINT=
R2_ACCESS_KEY_ID=
R2_SECRET_ACCESS_KEY=
R2_BUCKET=

# OpenAI (required for agent)
OPENAI_API_KEY=

# Twilio (required for SMS auth)
TWILIO_ACCOUNT_SID=
TWILIO_AUTH_TOKEN=
TWILIO_PHONE_NUMBER=

# Optional
APP_URL=http://localhost:3000
PORT=8787
```

## Database Schema

Five tables in Neon Postgres:

### users
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| phone | VARCHAR(20) | UNIQUE NOT NULL |
| created_at | TIMESTAMPTZ | NOT NULL DEFAULT NOW() |
| updated_at | TIMESTAMPTZ | NOT NULL DEFAULT NOW() |

### persons
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| user_id | UUID | FK users.id NOT NULL |
| name | VARCHAR(100) | NOT NULL |
| relationship | VARCHAR(20) | NOT NULL |
| phone | VARCHAR(20) | NULLABLE |
| created_at | TIMESTAMPTZ | NOT NULL DEFAULT NOW() |

### invites
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| token | VARCHAR(32) | UNIQUE NOT NULL |
| creator_id | UUID | FK users.id NOT NULL |
| person_id | UUID | FK persons.id NOT NULL |
| status | VARCHAR(20) | NOT NULL DEFAULT 'pending' |
| expires_at | TIMESTAMPTZ | NOT NULL |
| created_at | TIMESTAMPTZ | NOT NULL DEFAULT NOW() |

### sessions
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| invite_id | UUID | FK invites.id NOT NULL |
| room_name | VARCHAR(100) | NOT NULL |
| status | VARCHAR(20) | NOT NULL DEFAULT 'waiting' |
| started_at | TIMESTAMPTZ | NULLABLE |
| ended_at | TIMESTAMPTZ | NULLABLE |
| created_at | TIMESTAMPTZ | NOT NULL DEFAULT NOW() |

### recordings
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PK, default random |
| session_id | UUID | FK sessions.id NOT NULL |
| storage_key | TEXT | NOT NULL |
| duration_seconds | INTEGER | NOT NULL |
| size_bytes | BIGINT | NOT NULL |
| created_at | TIMESTAMPTZ | NOT NULL DEFAULT NOW() |

## API Endpoints

Base URL: `http://localhost:8787`

### POST /api/invites
Create a new invite.

Request:
```json
{
  "personName": "string (1-100 chars)",
  "personPhone": "string (E.164 format, optional)",
  "relationship": "parent | grandparent | other"
}
```

Response:
```json
{
  "inviteId": "uuid",
  "inviteUrl": "string",
  "expiresAt": "ISO datetime"
}
```

### POST /api/livekit/token
Get a LiveKit access token.

Request:
```json
{
  "inviteToken": "string (32 chars)"
}
```

Response:
```json
{
  "token": "JWT string",
  "roomName": "string",
  "serverUrl": "wss://..."
}
```

### POST /api/webhooks/livekit
Receive LiveKit webhooks (egress events).

Request: LiveKit webhook payload

Response:
```json
{
  "received": true
}
```

### GET /health
Health check.

Response:
```json
{
  "status": "ok",
  "timestamp": "ISO datetime"
}
```

## Domain Schemas

All domain schemas defined in `shared/domain/src/schemas.ts` using Zod v4.

Import pattern:
```typescript
import * as z from "zod/v4";
import { UserSchema, type User } from "@ember/domain";
```

## Code Patterns

### API Route Pattern
```typescript
import { Hono } from "hono";
import { zValidator } from "@hono/zod-validator";
import * as z from "zod/v4";

const RequestSchema = z.object({ ... });

export const router = new Hono();

router.post("/", zValidator("json", RequestSchema), async (c) => {
  const body = c.req.valid("json");
  // Implementation
  return c.json({ ... });
});
```

### React Component Pattern
```typescript
type Props = {
  title: string;
  children: React.ReactNode;
};

export function Component({ title, children }: Props) {
  return <div>{children}</div>;
}
```

### Database Query Pattern
```typescript
import { createDb, tableName } from "../db/client.js";
import { eq } from "drizzle-orm";

const db = createDb(process.env.DATABASE_URL!);
const results = await db.select().from(tableName).where(eq(tableName.column, value));
```

## Commands

```bash
# Development
bun run dev          # Start web + api
bun run dev:web      # Start web only
bun run dev:api      # Start api only

# Build
bun run build        # Build all

# Test
bun run test         # Unit tests
bun run test:e2e     # Playwright E2E

# Code quality
bun run typecheck    # Type check
bun run lint         # Lint
bun run fmt          # Format

# Database
cd api && bun run db:generate  # Generate migrations
cd api && bun run db:push      # Apply migrations

# Agent
cd agent && lk agent deploy    # Deploy to LiveKit Cloud
```

## CI/CD

GitHub Actions runs on push/PR to main:
1. lint-and-typecheck
2. test
3. build (depends on 1, 2)
4. e2e (depends on 3)

## Deployment

| Service | Platform | Command |
|---------|----------|---------|
| web | Vercel | Connect GitHub, set root to `web/` |
| api | Cloudflare Workers or Fly.io | `wrangler deploy` or `flyctl deploy` |
| agent | LiveKit Cloud | `lk agent deploy` |

---

*This specification is the source of truth. Implementation must conform to these patterns.*
````

---

## Summary

**What you get:**
- Flat structure with clear ownership (web, api, agent, shared)
- Domain schemas separated from API contracts
- Bun workspaces for package linking (no extra tools needed)
- GitHub Actions CI with lint, typecheck, test, build, E2E
- Playwright for E2E tests
- Python agent with Dockerfile for LiveKit Cloud deployment
- Single spec document for coding agents

**What you don't have:**
- Unnecessary nesting (no apps/, packages/ wrappers)
- Extra build tools (no Just, Nx, Turborepo for MVP)
- Vendor lock-in (Vite builds run anywhere, Hono runs anywhere)

**Next action:** Run `bun install` from root, then `bun run dev`. You should see both the web app on :3000 and API on :8787 start successfully.



## Prompt:
11/25/2025, 12:26:25 PM

This makes more sense to me. I like this; let's encode it into a single comprehensive document that serves as the source of truth and is as formal as possible in terms of the engineering best practices and conventions and structure. But I would like to change it slightly to put it in the Monorapro structure, where I put apps in the apps folder (like the web and API), and there is a root-level, top-level folder that also contains contracts and other stuff (maybe we can call it a packages folder). Maybe that's the Monorapro structure convention. And I would like to encode all of this, including the code, into a single one-off prompt and a source of truth document for me to reference as a human user, but also AI will another this will just be an official document for engineering. This will also serve as a start of truth document for me to reference as a human user, but also AI will another this will just be an official document for engineering. This can be taken and appended, saved, and used for different projects, but this one should be the first focus on this one specifically. I do not think that apps and packages is unnecessary nesting because it just seems more sensible to me, and there are a lot of configuration and.env files on the root level that I want to keep clear of that clutter. Update to reflect that, and be very detailed and exact in the new source of truth, authoritative document. Pin the versions to the latest known versions (November 25th, 2025), use Context 7, 

Be sure to include Gherkin-like product-level considerations as well as the engineering ones for user flow. The engineering stuff will be in a separate section, but the product stuff will be in a separate section. Although I'm actually not sure if they should be combined as one, but they are different. I think I want to make that differentiation and keep them different spheres of domain. But tell me what is recommended here. My intention for separating out the engineering one vs. the product one is there are multiple reasons.
I need to communicate this product-level one with my co-founder who is not technical, so it will be easier to keep things simpler here and minimal. But then I also want a reusable engineering template that I will use for the first time on this Ember project for this instance of the skeleton and documentation. But going forward, I will freeze this for 90 days, and I want to be able to reuse this and reference it. That's why I'm separating it. Maybe this can be one document with separate sections so that I don't have to manage multiple things. Be clear on any architectural decisions and leave ADRs (even if concisely) that mention the core parts and rationale behind choices. And make explicit the goals, considerations, the principles, the conventions, the versions, the choices, selections. The use cases that we are trying to fulfill and our constraints and requirements generally. All of the shapes of the inputs, outputs, constraints for this general problem as well as a specific problem and my preferences and conventions and principles and workflows.



## Response:
11/25/2025, 12:32:49 PM

````plaintext
Thought process: Architected unified source-of-truth document with segregated product and engineering sections.

The user wants me to create a comprehensive source of truth document for their Ember project. Let me break down the requirements:

1. **Structure**: Use `apps/` folder for web and api, and `packages/` folder for shared code like domain contracts
2. **Purpose**: Single authoritative document that serves both as:
   - Product reference for non-technical co-founder
   - Engineering reference/template for AI agents and future projects
3. **Content needs**:
   - Product-level Gherkin-like user flows
   - Engineering specifications
   - ADRs (Architecture Decision Records)
   - Pinned versions (November 25, 2025 latest)
   - Goals, principles, conventions, constraints
   - Use cases, requirements
4. **Document organization**: They're asking whether to combine product + engineering into one doc with sections, or separate docs

Let me address the document organization question first:

**Recommendation: One document with clear sections**
- Easier to maintain (single source of truth)
- Product section at the top (accessible to co-founder, can stop reading there)
- Engineering section follows (detailed technical specs)
- ADRs as appendix
- Co-founder can share/read just Part 1 (Product)
- Engineers/AI agents use the whole document

Now I need to:
1. Look up latest versions using Context7 or web search for key technologies
2. Create the comprehensive document with:
   - Part 1: Product Specification (Gherkin-style user stories, flows)
   - Part 2: Engineering Specification (architecture, code patterns, etc.)
   - Part 3: ADRs
   - Appendices (environment setup, commands, etc.)

Let me search for the latest versions of key technologies first.
````

I'll create a comprehensive, authoritative document for you. First, let me verify the latest stable versions of key technologies as of November 25, 2025.

````plaintext
Web Search: Bun 1.3 release November 2025 latest version
````

> **Releases · oven-sh/bun** [github.com](https://github.com/oven-sh/bun/releases)
>
> **Bun v1.3.2 | Bun Blog** [bun.com](https://bun.com/blog/bun-v1.3.2)
>
> **Bun v1.3.3 | Bun Blog** [bun.com](https://bun.com/blog/bun-v1.3.3)
>
> **Bun 1.3 stuffs everything and kitchen sink into JS runtime • The Register** [theregister.com](https://www.theregister.com/2025/10/13/bun_13_full_of_features/)
>
> **Bun — A fast all-in-one JavaScript runtime** [bun.com](https://bun.com)
>
> **Web Development: Bun 1.3 Becomes Full-Stack JavaScript Runtime | heise online** [heise.de](https://www.heise.de/en/news/Web-Development-Bun-1-3-Becomes-Full-Stack-JavaScript-Runtime-10759717.html)
>
> **Bun | endoflife.date** [endoflife.date](https://endoflife.date/bun)
>
> **Blog | Bun** [bun.com](https://bun.com/blog)
>
> **Bun 1.3 | Bun Blog** [bun.com](https://bun.com/blog/bun-v1.3)
>
> **Bun 1.3 Release — JavaScript and TypeScript Runtime Environment** [suddo.io](https://suddo.io/news/025465-bun-1-3-release-javascript-typescript-runtime-environment)
>
````plaintext
Thought process

Good, I have confirmed Bun 1.3.3 is the latest as of November 21, 2025. Let me search for a few more key technologies to pin exact versions.
````

````plaintext
Web Search: TypeScript 5.7 release November 2025 latest stable version
````

> **Releases · microsoft/TypeScript** [github.com](https://github.com/microsoft/typescript/releases)
>
> **TypeScript: Documentation - TypeScript 5.9** [typescriptlang.org](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-5-9.html)
>
> **Announcing TypeScript 5.9 - TypeScript** [microsoft.com](https://devblogs.microsoft.com/typescript/announcing-typescript-5-9/)
>
> **TypeScript: Documentation - TypeScript 5.8** [typescriptlang.org](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-5-8.html)
>
> **typescript - npm** [npmjs.com](https://www.npmjs.com/package/typescript?activeTab=versions)
>
> **TypeScript** [microsoft.com](https://devblogs.microsoft.com/typescript/)
>
> **TypeScript 5.9 Brings Less Friction, More Features - The New Stack** [thenewstack.io](https://thenewstack.io/typescript-5-9-brings-less-friction-more-features/)
>
> **A Comprehensive List of TypeScript Stable Versions: What You Need to Know** [webdevtutor.net](https://www.webdevtutor.net/blog/typescript-stable-version-list)
>
> **Typescript 5.7 & 5.8 - New Features & Direct Execution** [javascript-conference.com](https://javascript-conference.com/blog/typescript-5-7-5-8-features-ecmascript-direct-execution/)
>
> **Microsoft has launched the beta for TypeScript 5.7 - Neowin** [neowin.net](https://www.neowin.net/news/microsoft-has-launched-the-beta-for-typescript-57/)
>
````plaintext
Thought process

Good, I've confirmed:
- TypeScript 5.9.3 is the latest (npm shows 5.9.3)
- TypeScript 5.7.3 is also available as a stable version

Let me search for more key technologies.
````

````plaintext
Web Search: Vite 6 release November 2025 latest stable version
````

> **Releases | Vite** [vite.dev](https://vite.dev/releases)
>
> **Releases · vitejs/vite** [github.com](https://github.com/vitejs/vite/releases)
>
> **Releases | Vite** [vite.dev](https://v4.vite.dev/releases)
>
> **Vite 6.0 is out! | Vite** [vite.dev](https://vite.dev/blog/announcing-vite6)
>
> **Vite 7.0 is out! | Vite** [vite.dev](https://vite.dev/blog/announcing-vite7)
>
> **vite - npm** [npmjs.com](https://www.npmjs.com/package/vite?activeTab=versions)
>
> **Vite 6 · vitejs/vite · Discussion #15886** [github.com](https://github.com/vitejs/vite/discussions/15886)
>
> **Vite ⚡ on X: "vite@6.0.0-beta.10 is out! This is a big one! We plan to release v6 stable as soon as vite-ecosystem-ci is green, so if you have feedback, especially about Environment API please let us know quickly. Learn more about what's new at the v6 migration guide https://t.co/7aVn5dZM11" / X** [x.com](https://x.com/vite_js/status/1857094381259399594?lang=en)
>
> **Getting Started | Vite** [vite.dev](https://vite.dev/guide/)
>
> **Release Vite 6.0. This release of Vite 6.0 introduces a… | by Onix React | Medium** [medium.com](https://medium.com/@onix_react/release-vite-6-0-fe039e69e0ad)
>
````plaintext
Thought process

Good, Vite 7.2.4 is the latest as of 5 days ago. Now let me search for a few more key versions.
````

````plaintext
Web Search: HonoJS latest version November 2025
````

> **Releases · honojs/hono** [github.com](https://github.com/honojs/hono/releases)
>
> **hono - npm** [npmjs.com](https://www.npmjs.com/package/hono)
>
> **Hono - Web framework built on Web Standards** [hono.dev](https://hono.dev/)
>
> **Hono · GitHub** [github.com](https://github.com/honojs)
>
> **@hono/node-server - npm** [npmjs.com](https://www.npmjs.com/package/@hono/node-server?activeTab=versions)
>
> **Hono.js: The Next-Gen Node.js Framework | Leapcell** [leapcell.io](https://leapcell.io/blog/honojs-next-gen-nodejs-framework)
>
> **GitHub - honojs/honox: HonoX - Hono based meta framework** [github.com](https://github.com/honojs/honox)
>
> **Node.js - Hono** [hono.dev](https://hono.dev/docs/getting-started/nodejs)
>
> **@hono/node-ws - npm** [npmjs.com](https://www.npmjs.com/package/@hono/node-ws)
>
> **Hono.js: The Next-Gen Node.js Framework | by Leapcell | Medium** [medium.com](https://leapcell.medium.com/hono-js-the-next-gen-node-js-framework-a7e8896b2c76)
>
````plaintext
Thought process

Good, I have Hono 4.10.6 as the latest. Let me search for a few more key technologies.
````

````plaintext
Web Search: Drizzle ORM latest version November 2025
````

> **Drizzle ORM - Latest releases** [drizzle.team](https://orm.drizzle.team/docs/latest-releases)
>
> **Releases · drizzle-team/drizzle-orm** [github.com](https://github.com/drizzle-team/drizzle-orm/releases)
>
> **Drizzle ORM - next gen TypeScript ORM.** [drizzle.team](https://orm.drizzle.team/)
>
> **drizzle-orm - npm** [npmjs.com](https://www.npmjs.com/package/drizzle-orm)
>
> **Drizzle ORM - Update** [drizzle.team](https://orm.drizzle.team/docs/update)
>
> **GitHub - drizzle-team/drizzle-orm: ORM** [github.com](https://github.com/drizzle-team/drizzle-orm)
>
> **drizzle-orm: Complete Guide & Documentation [2025]** [generalistprogrammer.com](https://generalistprogrammer.com/tutorials/drizzle-orm-npm-package-guide)
>
> **Drizzle ORM - v1 Roadmap** [drizzle.team](https://orm.drizzle.team/roadmap)
>
> **Drizzle ORM download | SourceForge.net** [sourceforge.net](https://sourceforge.net/projects/drizzle-orm.mirror/)
>
> **Drizzle ORM PostgreSQL Best Practices Guide (2025) · GitHub** [github.com](https://gist.github.com/productdevbook/7c9ce3bbeb96b3fabc3c7c2aa2abc717)
>
````plaintext
Thought process

Good, Drizzle ORM 0.44.7 is the latest. Let me search for a few more key technologies - LiveKit, React, and Zod.
````

````plaintext
Web Search: React 19 latest stable version November 2025
````

> **React Versions – React** [react.dev](https://react.dev/versions)
>
> **React v19 – React** [react.dev](https://react.dev/blog/2024/12/05/react-19)
>
> **Releases · facebook/react** [github.com](https://github.com/facebook/react/releases)
>
> **React 19.2 – React** [react.dev](https://react.dev/blog/2025/10/01/react-19-2)
>
> **React 19 is now stable ! What's New (2025)** [medium.com](https://medium.com/@theNewGenCoder/react-19-is-now-stable-whats-new-2025-bbfa4b7aa092)
>
> **React 19 Stable Release: What’s New and How to Upgrade - DEV Community** [dev.to](https://dev.to/gladiatorsbattle/react-19-stable-release-whats-new-and-how-to-upgrade-299d)
>
> **React 19 : New Features and Updates - GeeksforGeeks** [geeksforgeeks.org](https://www.geeksforgeeks.org/reactjs/react-19-new-features-and-updates/)
>
> **React | endoflife.date** [endoflife.date](https://endoflife.date/react)
>
> **React Native 0.78 - React 19 and more · React Native** [reactnative.dev](https://reactnative.dev/blog/2025/02/19/react-native-0.78)
>
> **React latest version – React 18 is bringing concurrent mode** [tsh.io](https://tsh.io/blog/react-latest-version)
>
````plaintext
Thought process

Good, React 19.2.0 is the latest (released October 2025). Now let me search for Zod and LiveKit agents.
````

````plaintext
Web Search: Zod v4 latest version November 2025 npm
````

> **Release notes | Zod** [zod.dev](https://zod.dev/v4)
>
> **zod - npm** [npmjs.com](https://www.npmjs.com/package/zod)
>
> **Zod v4 Available with Major Performance Improvements and Introduction of Zod Mini - InfoQ** [infoq.com](https://www.infoq.com/news/2025/08/zod-v4-available/)
>
> **For library authors | Zod** [zod.dev](https://zod.dev/library-authors)
>
> **Versioning | Zod** [zod.dev](https://zod.dev/v4/versioning)
>
> **@abyrd9/zod-form-data - npm** [npmjs.com](https://www.npmjs.com/package/@abyrd9/zod-form-data)
>
> **Releases · colinhacks/zod** [github.com](https://github.com/colinhacks/zod/releases)
>
> **Zod 4 Release and Migration | colinhacks/zod | DeepWiki** [deepwiki.com](https://deepwiki.com/colinhacks/zod/5.4-zod-4-release-and-migration)
>
> **Mastra Changelog 2025-09-08 | Mastra Blog** [mastra.ai](https://mastra.ai/blog/changelog-2025-09-08)
>
> **Migration guide | Zod** [zod.dev](https://zod.dev/v4/changelog)
>
````plaintext
Thought process

Good, now I have most of the version information. Let me check the latest LiveKit agent version.
````

````plaintext
Web Search: livekit-agents python package latest version November 2025
````

> **LiveKit Agents | LiveKit docs** [livekit.io](https://docs.livekit.io/agents/)
>
> **livekit-agents · PyPI** [pypi.org](https://pypi.org/project/livekit-agents/)
>
> **GitHub - livekit/agents: A powerful framework for building realtime voice AI agents 🤖🎙️📹** [github.com](https://github.com/livekit/agents)
>
> **livekit · PyPI** [pypi.org](https://pypi.org/project/livekit/)
>
> **Releases · livekit/agents** [github.com](https://github.com/livekit/agents/releases)
>
> **livekit.agents API documentation** [livekit.io](https://docs.livekit.io/reference/python/v1/livekit/agents/)
>
> **Models | LiveKit docs** [livekit.io](https://docs.livekit.io/agents/models/)
>
> **Agents v0.x migration guide - Python | LiveKit docs** [livekit.io](https://docs.livekit.io/agents/v0-migration/python/)
>
> **livekit-plugins-openai · PyPI** [pypi.org](https://pypi.org/project/livekit-plugins-openai/)
>
> **livekit-plugins-turn-detector · PyPI** [pypi.org](https://pypi.org/project/livekit-plugins-turn-detector/)
>
````plaintext
Thought process: Synthesized versioned dependencies and architected comprehensive engineering documentation framework.

I now have all the latest version information I need. Let me compile the comprehensive document. I'll address the user's questions:

1. **Document Organization**: I'll recommend a single document with clear sections since it's easier to maintain and the product section can be read independently by the co-founder.

2. **Structure**: Use the `apps/` and `packages/` folder convention as requested.

3. **Versions Verified**:
   - Bun: 1.3.3 (Nov 21, 2025)
   - TypeScript: 5.9.3 (latest stable)
   - Vite: 7.2.4 (latest stable)
   - React: 19.2.0 (Oct 1, 2025)
   - Hono: 4.10.6 (11 days ago)
   - Drizzle ORM: 0.44.7 (1 month ago)
   - Zod: 4.0.0+ (stable, use `zod/v4` subpath from ^3.25.0)
   - LiveKit Agents: 1.3.3 (Nov 19, 2025)

Now let me create the comprehensive document.
````

Now I have all the verified version information. Let me create the comprehensive source-of-truth document.

## Document Organization Recommendation

**Single document with clear sections is recommended.** Here's why:

1. **Single source of truth**: One file to maintain, update, and reference
2. **Progressive disclosure**: Product section first (co-founder stops here), engineering follows (AI/devs continue)
3. **Cross-references work**: ADRs can reference both product requirements and technical decisions
4. **Version control**: Single document means single commit history for traceability
5. **Reusability**: The engineering sections (Part 2-4) can be extracted and templated for other projects; the product section (Part 1) is project-specific

**Document structure:**
- **Part 1: Product Specification** — Gherkin-style user stories, non-technical, co-founder-readable
- **Part 2: Engineering Specification** — Architecture, stack, conventions, code patterns
- **Part 3: Architecture Decision Records (ADRs)** — Concise decision log with rationale
- **Part 4: Appendices** — Environment setup, commands, checklists

Now let me create the document:

````plaintext
Create File: Creating the comprehensive SPEC.md source-of-truth document for Ember project with product and engineering specifications, ADRs, and implementation details.
````



## Prompt:
11/25/2025, 1:04:43 PM

````plaintext
Thought process: Reconciled document creation with user's monorepo structure preferences.

The user is asking me to confirm that I've created the document they requested. Looking at my previous response, I did create a comprehensive SPEC.md file at `/home/claude/SPEC.md`. 

However, the user seems to be repeating their original request, which suggests they may not have seen my response or want me to confirm/elaborate on what I created.

Let me re-read their message more carefully. They're saying "This makes more sense to me. I like this" - which suggests they're responding to something I said earlier in the conversation (likely the previous context about the flat vs apps/packages structure discussion).

Wait - looking at the conversation flow, this appears to be a duplicate or repeated message from the user. They're re-stating the same requirements I already addressed in the document I just created.

Let me check what I should do:
1. The document I created already includes the apps/ and packages/ structure they requested
2. It includes Gherkin-style product specifications
3. It includes engineering specifications
4. It includes ADRs
5. It has pinned versions based on my web searches

So I should:
1. Confirm that the document has been created
2. Summarize what's in it
3. Offer to move it to the outputs folder so they can download it
4. Perhaps highlight the key features that address their specific concerns

Let me provide a clear, helpful response that summarizes what was created and offers next steps.
````

I've created the comprehensive SPEC.md document. Let me move it to the outputs folder so you can download it, and provide a summary of what's included.

````plaintext
Bash Tool: Copy the SPEC.md to outputs for download
````

````plaintext
Thought process: Synthesized comprehensive monorepo architecture with dual documentation frameworks.

The user has received a duplicate/repeated message. Let me provide a clear summary of what I created and confirm it addresses all their requirements.
````

[View your specification document](computer:///mnt/user-data/outputs/SPEC.md)

## TL;DR

Created a **comprehensive 800+ line SPEC.md** with verified November 2025 versions, `apps/` + `packages/` monorepo structure, Gherkin product specs, full engineering specification, and 10 concise ADRs.

---

## What's Included

**Part 1: Product Specification** (lines 30-150)
- Vision and core insight (social triggers = 60-70% completion)
- Target user personas (Child/Creator, Parent/Grandparent)
- MVP scope with explicit exclusions
- **Gherkin scenarios** for all 4 features: Invite Creation, Recording Experience, Storage, Playback
- Success metrics with targets
- Constraints table (web-only, English-only, 7-day expiry, etc.)

**Part 2: Engineering Specification** (lines 150-550)
- 5 core principles (Own the Build, Own the Data, etc.)
- Technology stack with **pinned versions** verified today:
  - Bun 1.3.3, TypeScript 5.9.x, Zod v4 (via `"zod/v4"` import)
  - React 19.2.x, Vite 7.2.x, HonoJS 4.10.x
  - Drizzle 0.44.x, livekit-agents 1.3.x, Python 3.12
- Full **`apps/` + `packages/` monorepo structure** (your preference)
- Complete database schema (5 tables with all columns/constraints)
- API specification with request/response schemas
- Code patterns (Zod schemas, Hono routes, React components, Drizzle queries, Python agent)
- Testing strategy and naming conventions
- Environment variables reference
- Deployment targets

**Part 3: Architecture Decision Records** (lines 550-700)
- 10 ADRs with Status, Context, Decision, Rationale, Consequences
- ADR-001: apps/ + packages/ monorepo structure
- ADR-002: Vite + React over Next.js
- ADR-003: HonoJS for API
- ADR-004: Drizzle over Prisma
- ADR-005: BetterAuth (self-hosted)
- ADR-006: LiveKit Cloud
- ADR-007: Cloudflare R2
- ADR-008: Zod v4 via subpath
- ADR-009: Python for AI agent
- ADR-010: Bun workspaces without Turborepo

**Part 4: Appendices** (lines 700-850)
- Complete command reference
- Setup checklist (prerequisites, accounts, local setup)
- Coding conventions (TypeScript, imports, error handling, git commits)
- Troubleshooting guide

---

## Your Questions Addressed

**Single vs. separate documents?**
→ **Recommendation: Single document with clear sections** (what I created). Rationale in document header: your co-founder reads Part 1 only, engineers read Parts 1-4, AI agents get the whole thing. Single file = single version control history, no sync issues.

**apps/ and packages/ nesting?**
→ Included exactly as you requested. Root stays clean (just config files), deployable apps in `apps/`, shared code in `packages/`.

**Reusability?**
→ Parts 2-4 are written to be extractable as a template. The Ember-specific product requirements are isolated in Part 1. The 90-day version freeze is documented in the header.

---

## Next Actions

1. **Download** the SPEC.md from the link above
2. **Review** Part 1 with your co-founder (product validation)
3. **Confirm** the ADR decisions still align with your thinking
4. When ready, I can **scaffold the actual codebase** following this spec



## Response:
11/25/2025, 1:02:29 PM

Audit the spec and improve it to its best version by fixing any found issues or inconsistencies or potential improvements and simplifcations or optimizations for clean concise powerful e2e comprehensive. And I already use LiveKit Agent Node.js starter, but you recommended python one - it does seem more mature but i prefer sticking with typescript so let's use nodejs Livekit AI agent unless python ai agent significantly better.



